{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "GPU_Training-Alias-Free_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOplZA+hj+pzZS8n6xab1ol",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/duskvirkus/alias-free-gan/blob/devel/notebooks/GPU_Training_Alias_Free_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Training - Alias-Free GAN\n",
        "by duskvirkus\n",
        "\n",
        "This is a notebook for training Alias-Free GAN on a Colab GPU instance.\n",
        "\n",
        "Repository: https://github.com/duskvirkus/alias-free-gan"
      ],
      "metadata": {
        "id": "iooMpU0wSq1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU check\n",
        "\n",
        "If this fails change the runtime type in `Runtime > Change runtime type > Select GPU`."
      ],
      "metadata": {
        "id": "f3ygaIX_TP7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!nvidia-smi -L"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-d79f0a3f-4bb2-e6de-74e4-0274ee6a17ec)\n"
          ]
        }
      ],
      "metadata": {
        "id": "ZFKRHS3TTPbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6a82132-cb65-486e-fa1e-1ec8f0b0c7ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect Google Drive\n",
        "\n",
        "This notebook is designed to be used with google drive connected. If you'd like to use it without google drive you'll have to make changes.\n",
        "\n",
        "The main reason behind this is Colab sessions automaticall shut off after a number of hours (~10 for free, ~20 for pro, ~24 pro+). This risks loosing training progress if it's not saved to persistent storage."
      ],
      "metadata": {
        "id": "iRc3UyhPTi_6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "metadata": {
        "id": "6t1M2VB4Tif6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89137096-b1b5-4e59-c812-be749790aff1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone / cd into Repository"
      ],
      "metadata": {
        "id": "zPv1ThsOU-Op"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import os\n",
        "drive_path = '/content/drive/MyDrive/'\n",
        "repo_container_dir = 'colab-alias-free-gan'\n",
        "repo_name = 'alias-free-gan'\n",
        "git_repo = 'https://github.com/duskvirkus/alias-free-gan.git'\n",
        "branch_name = 'devel'\n",
        "\n",
        "working_dir = os.path.join(drive_path, repo_container_dir, repo_name)\n",
        "\n",
        "if os.path.isdir(working_dir):\n",
        "  %cd {working_dir}\n",
        "else:\n",
        "  container_path = os.path.join(drive_path, repo_container_dir)\n",
        "  os.makedirs(container_path)\n",
        "  %cd {container_path}\n",
        "  !git clone --branch {branch_name} {git_repo}\n",
        "  %cd {repo_name}\n",
        "  !mkdir pretrained"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/colab-alias-free-gan\n",
            "Cloning into 'alias-free-gan'...\n",
            "remote: Enumerating objects: 1200, done.\u001b[K\n",
            "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 1200 (delta 127), reused 171 (delta 91), pack-reused 958\u001b[K\n",
            "Receiving objects: 100% (1200/1200), 73.51 MiB | 20.79 MiB/s, done.\n",
            "Resolving deltas: 100% (588/588), done.\n",
            "Checking out files: 100% (94/94), done.\n",
            "/content/drive/MyDrive/colab-alias-free-gan/alias-free-gan\n"
          ]
        }
      ],
      "metadata": {
        "id": "_NBaGNEbSqPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc766dd-e349-4d86-acc5-2d3f889f09cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependancies"
      ],
      "metadata": {
        "id": "z6qSNzMhXQta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "!python install.py"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.4.2-py3-none-any.whl (916 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 42.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 44.0 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 71 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 81 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 92 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 102 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 122 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 133 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 143 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 153 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 163 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 174 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 184 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 194 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 204 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 215 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 225 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 235 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 245 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 256 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 266 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 276 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 286 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 296 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 307 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 317 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 327 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 337 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 348 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 358 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 368 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 378 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 389 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 399 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 409 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 419 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 430 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 440 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 450 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 460 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 471 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 481 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 491 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 501 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 512 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 522 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 532 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 542 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 552 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 563 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 573 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 583 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 593 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 604 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 614 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 624 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 634 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 645 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 655 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 665 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 675 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 686 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 696 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 706 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 716 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 727 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 737 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 747 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 757 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 768 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 778 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 788 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 798 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 808 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 819 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 829 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 839 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 849 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 860 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 870 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 880 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 890 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 901 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 911 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 916 kB 12.6 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning-bolts\n",
            "  Downloading pytorch_lightning_bolts-0.3.2-py3-none-any.whl (253 kB)\n",
            "\u001b[K     |████████████████████████████████| 253 kB 58.1 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.12.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 53.3 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 77.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 52.5 MB/s \n",
            "\u001b[?25hCollecting pyhocon\n",
            "  Downloading pyhocon-0.3.58.tar.gz (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 69.7 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 86 kB/s \n",
            "\u001b[?25hCollecting opensimplex\n",
            "  Downloading opensimplex-0.3-py3-none-any.whl (15 kB)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Collecting torchmetrics>=0.4.0\n",
            "  Downloading torchmetrics-0.5.0-py3-none-any.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.7.4.3)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.9.0+cu102)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 12.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 37.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.6.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.5)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.34.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.39.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.6.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 71.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 70.1 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (21.2.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.10.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (8.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest) (0.7.1)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 67.6 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.5.0)\n",
            "Building wheels for collected packages: future, subprocess32, pyhocon, pathtools\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=3a3750a3f5e81f3784a0053817e14ce9df72c9239b664ac92f4866fd6e5673c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=1591bbffedc79c7e290de75dbe9f56f510aaa90178c1a06109bf405d215ec008\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pyhocon (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyhocon: filename=pyhocon-0.3.58-py3-none-any.whl size=19890 sha256=acc277c27d0437fb3202f421b11dc2cdc577bf35dc46257b4c229a3952381e8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/20/f9/ff360765ce6f9fc078d6599c10a8f36496e5b5011a29df1ae3\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=af752273746ca13f7870ec4485697243761d9a977cb8bbf5b0202882b675f5b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built future subprocess32 pyhocon pathtools\n",
            "Installing collected packages: multidict, yarl, async-timeout, smmap, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, gitdb, future, subprocess32, shortuuid, sentry-sdk, pytorch-lightning, pathtools, GitPython, docker-pycreds, configparser, wandb, pytorch-lightning-bolts, pyhocon, pydantic, opensimplex, opencv-python-headless, ninja\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed GitPython-3.1.18 PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 configparser-5.0.2 docker-pycreds-0.4.0 fsspec-2021.7.0 future-0.18.2 gitdb-4.0.7 multidict-5.1.0 ninja-1.10.2 opencv-python-headless-4.5.3.56 opensimplex-0.3 pathtools-0.1.2 pyDeprecate-0.3.1 pydantic-1.8.2 pyhocon-0.3.58 pytorch-lightning-1.4.2 pytorch-lightning-bolts-0.3.2 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 torchmetrics-0.5.0 wandb-0.12.0 yarl-1.6.3\n"
          ]
        }
      ],
      "metadata": {
        "id": "pZYccZIHSpNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e76795-036b-4096-b792-4ef58d613f06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Dataset\n",
        "\n",
        "You can skip this section if you already have a dataset in the correct format.\n",
        "\n",
        "Currently only supports datasets with only one of the following dimensions of images. 256 by 256 **or** 512 by 512 **or** 1024 by 1024\n",
        "\n",
        "Preparing your dataset for conversion. Tools to prep a data set are beyond the scope of this notebook dvschultz/dataset-tools(https://github.com/dvschultz/dataset-tools) is suggested to help with this process.\n",
        "\n",
        "Structure of your dataset:\n",
        "```\n",
        "dataset_root_dir # name of your dataset is suggested\n",
        "  |- sub_directory # anything (this has to do with labels which is an unsupported feature at current time)\n",
        "    |- image01.png\n",
        "    |- images_can_have_any_names.png\n",
        "    |- they_also_be.jpg\n",
        "    |...continued # Suggested minimum size is 1000+ images.\n",
        "```\n",
        "\n",
        "The above example would result in an input of `unconverted_dataset='path/to/dataset_root_dir'`"
      ],
      "metadata": {
        "id": "xdzlUBR5XanA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "unconverted_dataset = '/content/drive/MyDrive/dataset-creation/painterly-faces-v2'\n",
        "out_path = '/content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-256'\n",
        "dataset_size = 256 # one of the following 256, 512, 1024\n",
        "!python scripts/convert_dataset.py --size {dataset_size} {unconverted_dataset} {out_path}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Make dataset of image sizes: 256\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "1it [00:00,  1.60it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "1158it [06:45,  2.85it/s]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqswLFEkarPc",
        "outputId": "7e332047-f216-42a1-b07b-cf3a28335637"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Info on training options\n",
        "\n",
        "Most training options work rather well out of the box. See the training section for suggested arguments.\n",
        "\n",
        "You can see a full list of training options by running the following cell."
      ],
      "metadata": {
        "id": "D6Yc1QbacaId"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!python scripts/trainer.py --help"
      ],
      "outputs": [],
      "metadata": {
        "id": "yuc-24U3dH_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Results from training can be found in `results` directory.\n",
        "\n",
        "**Resume from Checkpoint**\n",
        "\n",
        "Set `--resume_from 'path/to/checkpoint.pt'`\n",
        "\n",
        "If resuming from a checkpoint that doesn't use the new kimg naming scheme use `--start_kimg_count` to set the starting count manually.\n",
        "\n",
        "**Transfer Learning Options**\n",
        "\n",
        "See repository for transfer learning options. https://github.com/duskvirkus/alias-free-gan/blob/devel/pretrained_models.json\n",
        "\n",
        "Use `--resume_from 'model_name'`. wget is used to automatically download the pretrained models.\n",
        "\n",
        "**Training from Scratch**\n",
        "\n",
        "This is not recommended as transfer learning off of any model even if it's not related to your dataset will be faster and consume less resources. Unless there is no pretrained models or you have an explicit reason use transfer learning. To train from scratch simply leave resume blank, like so `--resume_from ''`.\n",
        "\n",
        "**Augmentations**\n",
        "\n",
        "Use `--augment True` to enable augmentations with `AdaptiveAugmentation`. See help for more options.\n",
        "\n",
        "### Suggested Batch Size\n",
        "\n",
        "For colab pro gpus (16GB) here are the suggested batch sizes:\n",
        "- 256: batch size 8 recommended\n",
        "- 512: batch size 4? recommended\n",
        "- 1024: batch size 4 for (p100) or 2 for (v100)\n",
        "\n",
        "Feel free to play around to see if you can get things higher. For the best performance try to keep batch in powers of 2.\n",
        "\n",
        "### Trouble Shooting\n",
        "\n",
        "If you get a cuda out of memory error try reducing the `batch`.\n",
        "\n",
        "If you get another error please report it at https://github.com/duskvirkus/alias-free-gan/issues/new\n",
        "\n",
        "If the model makes it through the first epoch you're unlike to encounter any errors after that.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EMt7IazBas5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "model_size = 256\n",
        "dataset_location = '/content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-256'\n",
        "resume = 'rosinality-ffhq-800k'\n",
        "batch_size = 8\n",
        "augmentations = True # ada\n",
        "\n",
        "sample_frequency = 1 # in kimgs or thousands of images\n",
        "checkpoint_frequency = 4 # in kimgs or thousands of images"
      ],
      "outputs": [],
      "metadata": {
        "id": "rI69L2vybsPr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "!python scripts/trainer.py \\\n",
        "  --gpus 1 \\\n",
        "  --max_epochs 1000000 \\\n",
        "  --accumulate_grad_batches 4 \\\n",
        "  --size {model_size} \\\n",
        "  --dataset_path {dataset_location} \\\n",
        "  --resume_from {resume} \\\n",
        "  --batch {batch_size} \\\n",
        "  --save_sample_every_kimgs {sample_frequency} \\\n",
        "  --save_checkpoint_every_kimgs {checkpoint_frequency} \\\n",
        "  --augment {augmentations}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Alias-Free GAN version: 1.0.0\n",
            "\n",
            "\n",
            "Licence and compensation information for rosinality-ffhq-800k pretrained model: test information\n",
            "\n",
            "\n",
            "Dataset path: /content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-256\n",
            "Initialized MultiResolutionDataset dataset with 1158 images\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name          | Type          | Params\n",
            "------------------------------------------------\n",
            "0 | generator     | Generator     | 17.3 M\n",
            "1 | g_ema         | Generator     | 17.3 M\n",
            "2 | discriminator | Discriminator | 28.9 M\n",
            "------------------------------------------------\n",
            "63.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "63.5 M    Total params\n",
            "253.864   Total estimated model params size (MB)\n",
            "Training: -1it [00:00, ?it/s]\n",
            "\n",
            "Resuming from: /content/drive/My Drive/colab-alias-free-gan/alias-free-gan/scripts/../pretrained/rosinality-ffhq-800k.pt\n",
            "\n",
            "AlignFreeGAN device: cuda:0\n",
            "\n",
            "\n",
            "Epoch 0:   0% 0/144 [00:00<00:00, 4568.96it/s]  /content/drive/My Drive/colab-alias-free-gan/alias-free-gan/scripts/../src/stylegan2/op/conv2d_gradfix.py:89: UserWarning: conv2d_gradfix not supported on PyTorch 1.9.0+cu102. Falling back to torch.nn.functional.conv2d().\n",
            "  f\"conv2d_gradfix not supported on PyTorch {torch.__version__}. Falling back to torch.nn.functional.conv2d().\"\n",
            "Epoch 5:  14% 20/144 [00:20<01:59,  1.03it/s, kimgs=1.480, r_t_stat=1.000, ada_aug_p=0.006784]/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1047: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "Epoch 5:  14% 20/144 [00:40<04:00,  1.94s/it, kimgs=1.480, r_t_stat=1.000, ada_aug_p=0.006784]\n"
          ]
        }
      ],
      "metadata": {
        "id": "avx9vyhlczji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a81d6b-32ec-4d9e-e118-9e3a28045574"
      }
    }
  ]
}