{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python install.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/drive/MyDrive/afg-lightning-devel-tpus/alias-free-gan-pytorch/datasets  /content/drive/MyDrive/afg-lightning-devel-arrayfire/alias-free-gan-pytorch-lightning/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make dataset of image sizes: 256\n",
      "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "32it [00:01, 25.56it/s]\n"
     ]
    }
   ],
   "source": [
    "!python src/prepare_data.py --out /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/ci/flowers-test-dataset-32-256 --n_worker 2 --size 256 /content/drive/MyDrive/dataset-creation/treeflowers/tree-flowers-32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: trainer.py [-h] --dataset_path DATASET_PATH --size SIZE [--batch BATCH]\n",
      "                  [--n_samples N_SAMPLES] [--lr_g LR_G] [--lr_d LR_D]\n",
      "                  [--d_reg_every D_REG_EVERY] [--r1 R1] [--augment AUGMENT]\n",
      "                  [--argument_p ARGUMENT_P] [--ada_target ADA_TARGET]\n",
      "                  [--ada_length ADA_LENGTH] [--ada_every ADA_EVERY]\n",
      "                  [--logger [LOGGER]]\n",
      "                  [--checkpoint_callback [CHECKPOINT_CALLBACK]]\n",
      "                  [--default_root_dir DEFAULT_ROOT_DIR]\n",
      "                  [--gradient_clip_val GRADIENT_CLIP_VAL]\n",
      "                  [--gradient_clip_algorithm GRADIENT_CLIP_ALGORITHM]\n",
      "                  [--process_position PROCESS_POSITION]\n",
      "                  [--num_nodes NUM_NODES] [--num_processes NUM_PROCESSES]\n",
      "                  [--gpus GPUS] [--auto_select_gpus [AUTO_SELECT_GPUS]]\n",
      "                  [--tpu_cores TPU_CORES] [--log_gpu_memory LOG_GPU_MEMORY]\n",
      "                  [--progress_bar_refresh_rate PROGRESS_BAR_REFRESH_RATE]\n",
      "                  [--overfit_batches OVERFIT_BATCHES]\n",
      "                  [--track_grad_norm TRACK_GRAD_NORM]\n",
      "                  [--check_val_every_n_epoch CHECK_VAL_EVERY_N_EPOCH]\n",
      "                  [--fast_dev_run [FAST_DEV_RUN]]\n",
      "                  [--accumulate_grad_batches ACCUMULATE_GRAD_BATCHES]\n",
      "                  [--max_epochs MAX_EPOCHS] [--min_epochs MIN_EPOCHS]\n",
      "                  [--max_steps MAX_STEPS] [--min_steps MIN_STEPS]\n",
      "                  [--max_time MAX_TIME]\n",
      "                  [--limit_train_batches LIMIT_TRAIN_BATCHES]\n",
      "                  [--limit_val_batches LIMIT_VAL_BATCHES]\n",
      "                  [--limit_test_batches LIMIT_TEST_BATCHES]\n",
      "                  [--limit_predict_batches LIMIT_PREDICT_BATCHES]\n",
      "                  [--val_check_interval VAL_CHECK_INTERVAL]\n",
      "                  [--flush_logs_every_n_steps FLUSH_LOGS_EVERY_N_STEPS]\n",
      "                  [--log_every_n_steps LOG_EVERY_N_STEPS]\n",
      "                  [--accelerator ACCELERATOR]\n",
      "                  [--sync_batchnorm [SYNC_BATCHNORM]] [--precision PRECISION]\n",
      "                  [--weights_summary WEIGHTS_SUMMARY]\n",
      "                  [--weights_save_path WEIGHTS_SAVE_PATH]\n",
      "                  [--num_sanity_val_steps NUM_SANITY_VAL_STEPS]\n",
      "                  [--truncated_bptt_steps TRUNCATED_BPTT_STEPS]\n",
      "                  [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                  [--profiler PROFILER] [--benchmark [BENCHMARK]]\n",
      "                  [--deterministic [DETERMINISTIC]]\n",
      "                  [--reload_dataloaders_every_epoch [RELOAD_DATALOADERS_EVERY_EPOCH]]\n",
      "                  [--auto_lr_find [AUTO_LR_FIND]]\n",
      "                  [--replace_sampler_ddp [REPLACE_SAMPLER_DDP]]\n",
      "                  [--terminate_on_nan [TERMINATE_ON_NAN]]\n",
      "                  [--auto_scale_batch_size [AUTO_SCALE_BATCH_SIZE]]\n",
      "                  [--prepare_data_per_node [PREPARE_DATA_PER_NODE]]\n",
      "                  [--plugins PLUGINS] [--amp_backend AMP_BACKEND]\n",
      "                  [--amp_level AMP_LEVEL]\n",
      "                  [--distributed_backend DISTRIBUTED_BACKEND]\n",
      "                  [--move_metrics_to_cpu [MOVE_METRICS_TO_CPU]]\n",
      "                  [--multiple_trainloader_mode MULTIPLE_TRAINLOADER_MODE]\n",
      "                  [--stochastic_weight_avg [STOCHASTIC_WEIGHT_AVG]]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "Trainer Script:\n",
      "  --dataset_path DATASET_PATH\n",
      "                        Path to dataset. Required!\n",
      "\n",
      "AliasFreeGAN Model:\n",
      "  --size SIZE           Pixel dimension of model. Must be 256, 512, or 1024.\n",
      "                        Required!\n",
      "  --batch BATCH         Batch size. Will be overridden if\n",
      "                        --auto_scale_batch_size is used. (default: 16)\n",
      "  --n_samples N_SAMPLES\n",
      "                        Number of samples to generate in training process.\n",
      "                        (default: 9)\n",
      "  --lr_g LR_G           Generator learning rate. (default: 0.002)\n",
      "  --lr_d LR_D           Discriminator learning rate. (default: 0.002)\n",
      "  --d_reg_every D_REG_EVERY\n",
      "                        Regularize discriminator ever _ iters. (default: 16)\n",
      "  --r1 R1               R1 regularization weights. (default: 10.0)\n",
      "  --augment AUGMENT     Use augmentations. (default: False)\n",
      "  --argument_p ARGUMENT_P\n",
      "                        (default: 0.0)\n",
      "  --ada_target ADA_TARGET\n",
      "                        (default: 0.6)\n",
      "  --ada_length ADA_LENGTH\n",
      "                        (default: 500000)\n",
      "  --ada_every ADA_EVERY\n",
      "                        (default: 256)\n",
      "\n",
      "pl.Trainer:\n",
      "  --logger [LOGGER]     Logger (or iterable collection of loggers) for\n",
      "                        experiment tracking. A ``True`` value uses the default\n",
      "                        ``TensorBoardLogger``. ``False`` will disable logging.\n",
      "  --checkpoint_callback [CHECKPOINT_CALLBACK]\n",
      "                        If ``True``, enable checkpointing. It will configure a\n",
      "                        default ModelCheckpoint callback if there is no user-\n",
      "                        defined ModelCheckpoint in :paramref:`~pytorch_lightni\n",
      "                        ng.trainer.trainer.Trainer.callbacks`.\n",
      "  --default_root_dir DEFAULT_ROOT_DIR\n",
      "                        Default path for logs and weights when no\n",
      "                        logger/ckpt_callback passed. Default: ``os.getcwd()``.\n",
      "                        Can be remote file paths such as `s3://mybucket/path`\n",
      "                        or 'hdfs://path/'\n",
      "  --gradient_clip_val GRADIENT_CLIP_VAL\n",
      "                        0 means don't clip.\n",
      "  --gradient_clip_algorithm GRADIENT_CLIP_ALGORITHM\n",
      "                        'value' means clip_by_value, 'norm' means\n",
      "                        clip_by_norm. Default: 'norm'\n",
      "  --process_position PROCESS_POSITION\n",
      "                        orders the progress bar when running multiple models\n",
      "                        on same machine.\n",
      "  --num_nodes NUM_NODES\n",
      "                        number of GPU nodes for distributed training.\n",
      "  --num_processes NUM_PROCESSES\n",
      "                        number of processes for distributed training with\n",
      "                        distributed_backend=\"ddp_cpu\"\n",
      "  --gpus GPUS           number of gpus to train on (int) or which GPUs to\n",
      "                        train on (list or str) applied per node\n",
      "  --auto_select_gpus [AUTO_SELECT_GPUS]\n",
      "                        If enabled and `gpus` is an integer, pick available\n",
      "                        gpus automatically. This is especially useful when\n",
      "                        GPUs are configured to be in \"exclusive mode\", such\n",
      "                        that only one process at a time can access them.\n",
      "  --tpu_cores TPU_CORES\n",
      "                        How many TPU cores to train on (1 or 8) / Single TPU\n",
      "                        to train on [1]\n",
      "  --log_gpu_memory LOG_GPU_MEMORY\n",
      "                        None, 'min_max', 'all'. Might slow performance\n",
      "  --progress_bar_refresh_rate PROGRESS_BAR_REFRESH_RATE\n",
      "                        How often to refresh progress bar (in steps). Value\n",
      "                        ``0`` disables progress bar. Ignored when a custom\n",
      "                        progress bar is passed to\n",
      "                        :paramref:`~Trainer.callbacks`. Default: None, means a\n",
      "                        suitable value will be chosen based on the environment\n",
      "                        (terminal, Google COLAB, etc.).\n",
      "  --overfit_batches OVERFIT_BATCHES\n",
      "                        Overfit a fraction of training data (float) or a set\n",
      "                        number of batches (int).\n",
      "  --track_grad_norm TRACK_GRAD_NORM\n",
      "                        -1 no tracking. Otherwise tracks that p-norm. May be\n",
      "                        set to 'inf' infinity-norm.\n",
      "  --check_val_every_n_epoch CHECK_VAL_EVERY_N_EPOCH\n",
      "                        Check val every n train epochs.\n",
      "  --fast_dev_run [FAST_DEV_RUN]\n",
      "                        runs n if set to ``n`` (int) else 1 if set to ``True``\n",
      "                        batch(es) of train, val and test to find any bugs (ie:\n",
      "                        a sort of unit test).\n",
      "  --accumulate_grad_batches ACCUMULATE_GRAD_BATCHES\n",
      "                        Accumulates grads every k batches or as set up in the\n",
      "                        dict.\n",
      "  --max_epochs MAX_EPOCHS\n",
      "                        Stop training once this number of epochs is reached.\n",
      "                        Disabled by default (None). If both max_epochs and\n",
      "                        max_steps are not specified, defaults to\n",
      "                        ``max_epochs`` = 1000.\n",
      "  --min_epochs MIN_EPOCHS\n",
      "                        Force training for at least these many epochs.\n",
      "                        Disabled by default (None). If both min_epochs and\n",
      "                        min_steps are not specified, defaults to\n",
      "                        ``min_epochs`` = 1.\n",
      "  --max_steps MAX_STEPS\n",
      "                        Stop training after this number of steps. Disabled by\n",
      "                        default (None).\n",
      "  --min_steps MIN_STEPS\n",
      "                        Force training for at least these number of steps.\n",
      "                        Disabled by default (None).\n",
      "  --max_time MAX_TIME   Stop training after this amount of time has passed.\n",
      "                        Disabled by default (None). The time duration can be\n",
      "                        specified in the format DD:HH:MM:SS (days, hours,\n",
      "                        minutes seconds), as a :class:`datetime.timedelta`, or\n",
      "                        a dictionary with keys that will be passed to\n",
      "                        :class:`datetime.timedelta`.\n",
      "  --limit_train_batches LIMIT_TRAIN_BATCHES\n",
      "                        How much of training dataset to check (float =\n",
      "                        fraction, int = num_batches)\n",
      "  --limit_val_batches LIMIT_VAL_BATCHES\n",
      "                        How much of validation dataset to check (float =\n",
      "                        fraction, int = num_batches)\n",
      "  --limit_test_batches LIMIT_TEST_BATCHES\n",
      "                        How much of test dataset to check (float = fraction,\n",
      "                        int = num_batches)\n",
      "  --limit_predict_batches LIMIT_PREDICT_BATCHES\n",
      "                        How much of prediction dataset to check (float =\n",
      "                        fraction, int = num_batches)\n",
      "  --val_check_interval VAL_CHECK_INTERVAL\n",
      "                        How often to check the validation set. Use float to\n",
      "                        check within a training epoch, use int to check every\n",
      "                        n steps (batches).\n",
      "  --flush_logs_every_n_steps FLUSH_LOGS_EVERY_N_STEPS\n",
      "                        How often to flush logs to disk (defaults to every 100\n",
      "                        steps).\n",
      "  --log_every_n_steps LOG_EVERY_N_STEPS\n",
      "                        How often to log within steps (defaults to every 50\n",
      "                        steps).\n",
      "  --accelerator ACCELERATOR\n",
      "                        Previously known as distributed_backend (dp, ddp,\n",
      "                        ddp2, etc...). Can also take in an accelerator object\n",
      "                        for custom hardware.\n",
      "  --sync_batchnorm [SYNC_BATCHNORM]\n",
      "                        Synchronize batch norm layers between process\n",
      "                        groups/whole world.\n",
      "  --precision PRECISION\n",
      "                        Double precision (64), full precision (32) or half\n",
      "                        precision (16). Can be used on CPU, GPU or TPUs.\n",
      "  --weights_summary WEIGHTS_SUMMARY\n",
      "                        Prints a summary of the weights when training begins.\n",
      "  --weights_save_path WEIGHTS_SAVE_PATH\n",
      "                        Where to save weights if specified. Will override\n",
      "                        default_root_dir for checkpoints only. Use this if for\n",
      "                        whatever reason you need the checkpoints stored in a\n",
      "                        different place than the logs written in\n",
      "                        `default_root_dir`. Can be remote file paths such as\n",
      "                        `s3://mybucket/path` or 'hdfs://path/' Defaults to\n",
      "                        `default_root_dir`.\n",
      "  --num_sanity_val_steps NUM_SANITY_VAL_STEPS\n",
      "                        Sanity check runs n validation batches before starting\n",
      "                        the training routine. Set it to `-1` to run all\n",
      "                        batches in all validation dataloaders.\n",
      "  --truncated_bptt_steps TRUNCATED_BPTT_STEPS\n",
      "                        Deprecated in v1.3 to be removed in 1.5. Please use :p\n",
      "                        aramref:`~pytorch_lightning.core.lightning.LightningMo\n",
      "                        dule.truncated_bptt_steps` instead.\n",
      "  --resume_from_checkpoint RESUME_FROM_CHECKPOINT\n",
      "                        Path/URL of the checkpoint from which training is\n",
      "                        resumed. If there is no checkpoint file at the path,\n",
      "                        start from scratch. If resuming from mid-epoch\n",
      "                        checkpoint, training will start from the beginning of\n",
      "                        the next epoch.\n",
      "  --profiler PROFILER   To profile individual steps during training and assist\n",
      "                        in identifying bottlenecks.\n",
      "  --benchmark [BENCHMARK]\n",
      "                        If true enables cudnn.benchmark.\n",
      "  --deterministic [DETERMINISTIC]\n",
      "                        If true enables cudnn.deterministic.\n",
      "  --reload_dataloaders_every_epoch [RELOAD_DATALOADERS_EVERY_EPOCH]\n",
      "                        Set to True to reload dataloaders every epoch.\n",
      "  --auto_lr_find [AUTO_LR_FIND]\n",
      "                        If set to True, will make trainer.tune() run a\n",
      "                        learning rate finder, trying to optimize initial\n",
      "                        learning for faster convergence. trainer.tune() method\n",
      "                        will set the suggested learning rate in self.lr or\n",
      "                        self.learning_rate in the LightningModule. To use a\n",
      "                        different key set a string instead of True with the\n",
      "                        key name.\n",
      "  --replace_sampler_ddp [REPLACE_SAMPLER_DDP]\n",
      "                        Explicitly enables or disables sampler replacement. If\n",
      "                        not specified this will toggled automatically when DDP\n",
      "                        is used. By default it will add ``shuffle=True`` for\n",
      "                        train sampler and ``shuffle=False`` for val/test\n",
      "                        sampler. If you want to customize it, you can set\n",
      "                        ``replace_sampler_ddp=False`` and add your own\n",
      "                        distributed sampler.\n",
      "  --terminate_on_nan [TERMINATE_ON_NAN]\n",
      "                        If set to True, will terminate training (by raising a\n",
      "                        `ValueError`) at the end of each training batch, if\n",
      "                        any of the parameters or the loss are NaN or +/-inf.\n",
      "  --auto_scale_batch_size [AUTO_SCALE_BATCH_SIZE]\n",
      "                        If set to True, will `initially` run a batch size\n",
      "                        finder trying to find the largest batch size that fits\n",
      "                        into memory. The result will be stored in\n",
      "                        self.batch_size in the LightningModule. Additionally,\n",
      "                        can be set to either `power` that estimates the batch\n",
      "                        size through a power search or `binsearch` that\n",
      "                        estimates the batch size through a binary search.\n",
      "  --prepare_data_per_node [PREPARE_DATA_PER_NODE]\n",
      "                        If True, each LOCAL_RANK=0 will call prepare data.\n",
      "                        Otherwise only NODE_RANK=0, LOCAL_RANK=0 will prepare\n",
      "                        data\n",
      "  --plugins PLUGINS     Plugins allow modification of core behavior like ddp\n",
      "                        and amp, and enable custom lightning plugins.\n",
      "  --amp_backend AMP_BACKEND\n",
      "                        The mixed precision backend to use (\"native\" or\n",
      "                        \"apex\")\n",
      "  --amp_level AMP_LEVEL\n",
      "                        The optimization level to use (O1, O2, etc...).\n",
      "  --distributed_backend DISTRIBUTED_BACKEND\n",
      "                        deprecated. Please use 'accelerator'\n",
      "  --move_metrics_to_cpu [MOVE_METRICS_TO_CPU]\n",
      "                        Whether to force internal logged metrics to be moved\n",
      "                        to cpu. This can save some gpu memory, but can make\n",
      "                        training slower. Use with attention.\n",
      "  --multiple_trainloader_mode MULTIPLE_TRAINLOADER_MODE\n",
      "                        How to loop over the datasets when there are multiple\n",
      "                        train loaders. In 'max_size_cycle' mode, the trainer\n",
      "                        ends one epoch when the largest dataset is traversed,\n",
      "                        and smaller datasets reload when running out of their\n",
      "                        data. In 'min_size' mode, all the datasets reload when\n",
      "                        reaching the minimum length of datasets.\n",
      "  --stochastic_weight_avg [STOCHASTIC_WEIGHT_AVG]\n",
      "                        Whether to use `Stochastic Weight Averaging (SWA)\n",
      "                        <https://pytorch.org/blog/pytorch-1.6-now-includes-\n",
      "                        stochastic-weight-averaging/>_`\n"
     ]
    }
   ],
   "source": [
    "!python scripts/trainer.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 256\n",
    "dataset_location = '/content/drive/MyDrive/afg-lightning-devel-arrayfire/alias-free-gan-pytorch-lightning/datasets/album-art-256/'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Namespace(accelerator=None, accumulate_grad_batches=1, ada_every=256, ada_length=500000, ada_target=0.6, amp_backend='native', amp_level='O2', argument_p=0.0, augment=False, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch=12, benchmark=False, check_val_every_n_epoch=1, checkpoint_callback=True, d_reg_every=16, dataset_path='/content/drive/MyDrive/afg-lightning-devel-arrayfire/alias-free-gan-pytorch-lightning/datasets/album-art-256/', default_root_dir=None, deterministic=False, distributed_backend=None, fast_dev_run=False, flush_logs_every_n_steps=100, gpus=1, gradient_clip_algorithm='norm', gradient_clip_val=0.0, limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr_d=0.002, lr_g=0.002, max_epochs=None, max_steps=None, max_time=None, min_epochs=None, min_steps=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', n_samples=12, num_nodes=1, num_processes=1, num_sanity_val_steps=2, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=None, r1=10.0, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, size=256, stochastic_weight_avg=False, sync_batchnorm=False, terminate_on_nan=False, tpu_cores=None, track_grad_norm=-1, truncated_bptt_steps=None, val_check_interval=1.0, weights_save_path=None, weights_summary='full')\n",
      "Dataset path: /content/drive/MyDrive/afg-lightning-devel-arrayfire/alias-free-gan-pytorch-lightning/datasets/album-art-256/\n",
      "Initialized MultiResolutionDataset dataset with 2145 images\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2021-07-19 22:27:24.263292: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\n",
      "    | Name                               | Type                | Params\n",
      "-----------------------------------------------------------------------------\n",
      "0   | generator                          | Generator           | 15.8 M\n",
      "1   | generator.style                    | Sequential          | 131 K \n",
      "2   | generator.style.0                  | PixelNorm           | 0     \n",
      "3   | generator.style.1                  | EqualLinear         | 65.8 K\n",
      "4   | generator.style.2                  | EqualLinear         | 65.8 K\n",
      "5   | generator.input                    | FourierFeature      | 0     \n",
      "6   | generator.affine_fourier           | EqualLinear         | 1.0 K \n",
      "7   | generator.conv1                    | EqualConv2d         | 262 K \n",
      "8   | generator.convs                    | ModuleList          | 15.4 M\n",
      "9   | generator.convs.0                  | AliasFreeConv       | 2.5 M \n",
      "10  | generator.convs.0.conv             | ModulatedConv2d     | 2.5 M \n",
      "11  | generator.convs.0.conv.modulation  | EqualLinear         | 131 K \n",
      "12  | generator.convs.0.activation       | AliasFreeActivation | 512   \n",
      "13  | generator.convs.1                  | AliasFreeConv       | 2.5 M \n",
      "14  | generator.convs.1.conv             | ModulatedConv2d     | 2.5 M \n",
      "15  | generator.convs.1.conv.modulation  | EqualLinear         | 131 K \n",
      "16  | generator.convs.1.activation       | AliasFreeActivation | 512   \n",
      "17  | generator.convs.2                  | AliasFreeConv       | 2.5 M \n",
      "18  | generator.convs.2.conv             | ModulatedConv2d     | 2.5 M \n",
      "19  | generator.convs.2.conv.modulation  | EqualLinear         | 131 K \n",
      "20  | generator.convs.2.activation       | AliasFreeActivation | 512   \n",
      "21  | generator.convs.3                  | AliasFreeConv       | 2.5 M \n",
      "22  | generator.convs.3.conv             | ModulatedConv2d     | 2.5 M \n",
      "23  | generator.convs.3.conv.modulation  | EqualLinear         | 131 K \n",
      "24  | generator.convs.3.activation       | AliasFreeActivation | 512   \n",
      "25  | generator.convs.4                  | AliasFreeConv       | 2.5 M \n",
      "26  | generator.convs.4.conv             | ModulatedConv2d     | 2.5 M \n",
      "27  | generator.convs.4.conv.modulation  | EqualLinear         | 131 K \n",
      "28  | generator.convs.4.activation       | AliasFreeActivation | 512   \n",
      "29  | generator.convs.5                  | AliasFreeConv       | 1.3 M \n",
      "30  | generator.convs.5.conv             | ModulatedConv2d     | 1.3 M \n",
      "31  | generator.convs.5.conv.modulation  | EqualLinear         | 131 K \n",
      "32  | generator.convs.5.activation       | AliasFreeActivation | 256   \n",
      "33  | generator.convs.6                  | AliasFreeConv       | 655 K \n",
      "34  | generator.convs.6.conv             | ModulatedConv2d     | 655 K \n",
      "35  | generator.convs.6.conv.modulation  | EqualLinear         | 65.8 K\n",
      "36  | generator.convs.6.activation       | AliasFreeActivation | 256   \n",
      "37  | generator.convs.7                  | AliasFreeConv       | 360 K \n",
      "38  | generator.convs.7.conv             | ModulatedConv2d     | 360 K \n",
      "39  | generator.convs.7.conv.modulation  | EqualLinear         | 65.8 K\n",
      "40  | generator.convs.7.activation       | AliasFreeActivation | 128   \n",
      "41  | generator.convs.8                  | AliasFreeConv       | 180 K \n",
      "42  | generator.convs.8.conv             | ModulatedConv2d     | 180 K \n",
      "43  | generator.convs.8.conv.modulation  | EqualLinear         | 32.9 K\n",
      "44  | generator.convs.8.activation       | AliasFreeActivation | 128   \n",
      "45  | generator.convs.9                  | AliasFreeConv       | 180 K \n",
      "46  | generator.convs.9.conv             | ModulatedConv2d     | 180 K \n",
      "47  | generator.convs.9.conv.modulation  | EqualLinear         | 32.9 K\n",
      "48  | generator.convs.9.activation       | AliasFreeActivation | 128   \n",
      "49  | generator.convs.10                 | AliasFreeConv       | 106 K \n",
      "50  | generator.convs.10.conv            | ModulatedConv2d     | 106 K \n",
      "51  | generator.convs.10.conv.modulation | EqualLinear         | 32.9 K\n",
      "52  | generator.convs.10.activation      | AliasFreeActivation | 64    \n",
      "53  | generator.convs.11                 | AliasFreeConv       | 53.4 K\n",
      "54  | generator.convs.11.conv            | ModulatedConv2d     | 53.3 K\n",
      "55  | generator.convs.11.conv.modulation | EqualLinear         | 16.4 K\n",
      "56  | generator.convs.11.activation      | AliasFreeActivation | 64    \n",
      "57  | generator.convs.12                 | AliasFreeConv       | 53.4 K\n",
      "58  | generator.convs.12.conv            | ModulatedConv2d     | 53.3 K\n",
      "59  | generator.convs.12.conv.modulation | EqualLinear         | 16.4 K\n",
      "60  | generator.convs.12.activation      | AliasFreeActivation | 64    \n",
      "61  | generator.convs.13                 | AliasFreeConv       | 53.4 K\n",
      "62  | generator.convs.13.conv            | ModulatedConv2d     | 53.3 K\n",
      "63  | generator.convs.13.conv.modulation | EqualLinear         | 16.4 K\n",
      "64  | generator.convs.13.activation      | AliasFreeActivation | 64    \n",
      "65  | generator.to_rgb                   | ToRGB               | 16.6 K\n",
      "66  | generator.to_rgb.conv              | ModulatedConv2d     | 16.6 K\n",
      "67  | generator.to_rgb.conv.modulation   | EqualLinear         | 16.4 K\n",
      "68  | g_ema                              | Generator           | 15.8 M\n",
      "69  | g_ema.style                        | Sequential          | 131 K \n",
      "70  | g_ema.style.0                      | PixelNorm           | 0     \n",
      "71  | g_ema.style.1                      | EqualLinear         | 65.8 K\n",
      "72  | g_ema.style.2                      | EqualLinear         | 65.8 K\n",
      "73  | g_ema.input                        | FourierFeature      | 0     \n",
      "74  | g_ema.affine_fourier               | EqualLinear         | 1.0 K \n",
      "75  | g_ema.conv1                        | EqualConv2d         | 262 K \n",
      "76  | g_ema.convs                        | ModuleList          | 15.4 M\n",
      "77  | g_ema.convs.0                      | AliasFreeConv       | 2.5 M \n",
      "78  | g_ema.convs.0.conv                 | ModulatedConv2d     | 2.5 M \n",
      "79  | g_ema.convs.0.conv.modulation      | EqualLinear         | 131 K \n",
      "80  | g_ema.convs.0.activation           | AliasFreeActivation | 512   \n",
      "81  | g_ema.convs.1                      | AliasFreeConv       | 2.5 M \n",
      "82  | g_ema.convs.1.conv                 | ModulatedConv2d     | 2.5 M \n",
      "83  | g_ema.convs.1.conv.modulation      | EqualLinear         | 131 K \n",
      "84  | g_ema.convs.1.activation           | AliasFreeActivation | 512   \n",
      "85  | g_ema.convs.2                      | AliasFreeConv       | 2.5 M \n",
      "86  | g_ema.convs.2.conv                 | ModulatedConv2d     | 2.5 M \n",
      "87  | g_ema.convs.2.conv.modulation      | EqualLinear         | 131 K \n",
      "88  | g_ema.convs.2.activation           | AliasFreeActivation | 512   \n",
      "89  | g_ema.convs.3                      | AliasFreeConv       | 2.5 M \n",
      "90  | g_ema.convs.3.conv                 | ModulatedConv2d     | 2.5 M \n",
      "91  | g_ema.convs.3.conv.modulation      | EqualLinear         | 131 K \n",
      "92  | g_ema.convs.3.activation           | AliasFreeActivation | 512   \n",
      "93  | g_ema.convs.4                      | AliasFreeConv       | 2.5 M \n",
      "94  | g_ema.convs.4.conv                 | ModulatedConv2d     | 2.5 M \n",
      "95  | g_ema.convs.4.conv.modulation      | EqualLinear         | 131 K \n",
      "96  | g_ema.convs.4.activation           | AliasFreeActivation | 512   \n",
      "97  | g_ema.convs.5                      | AliasFreeConv       | 1.3 M \n",
      "98  | g_ema.convs.5.conv                 | ModulatedConv2d     | 1.3 M \n",
      "99  | g_ema.convs.5.conv.modulation      | EqualLinear         | 131 K \n",
      "100 | g_ema.convs.5.activation           | AliasFreeActivation | 256   \n",
      "101 | g_ema.convs.6                      | AliasFreeConv       | 655 K \n",
      "102 | g_ema.convs.6.conv                 | ModulatedConv2d     | 655 K \n",
      "103 | g_ema.convs.6.conv.modulation      | EqualLinear         | 65.8 K\n",
      "104 | g_ema.convs.6.activation           | AliasFreeActivation | 256   \n",
      "105 | g_ema.convs.7                      | AliasFreeConv       | 360 K \n",
      "106 | g_ema.convs.7.conv                 | ModulatedConv2d     | 360 K \n",
      "107 | g_ema.convs.7.conv.modulation      | EqualLinear         | 65.8 K\n",
      "108 | g_ema.convs.7.activation           | AliasFreeActivation | 128   \n",
      "109 | g_ema.convs.8                      | AliasFreeConv       | 180 K \n",
      "110 | g_ema.convs.8.conv                 | ModulatedConv2d     | 180 K \n",
      "111 | g_ema.convs.8.conv.modulation      | EqualLinear         | 32.9 K\n",
      "112 | g_ema.convs.8.activation           | AliasFreeActivation | 128   \n",
      "113 | g_ema.convs.9                      | AliasFreeConv       | 180 K \n",
      "114 | g_ema.convs.9.conv                 | ModulatedConv2d     | 180 K \n",
      "115 | g_ema.convs.9.conv.modulation      | EqualLinear         | 32.9 K\n",
      "116 | g_ema.convs.9.activation           | AliasFreeActivation | 128   \n",
      "117 | g_ema.convs.10                     | AliasFreeConv       | 106 K \n",
      "118 | g_ema.convs.10.conv                | ModulatedConv2d     | 106 K \n",
      "119 | g_ema.convs.10.conv.modulation     | EqualLinear         | 32.9 K\n",
      "120 | g_ema.convs.10.activation          | AliasFreeActivation | 64    \n",
      "121 | g_ema.convs.11                     | AliasFreeConv       | 53.4 K\n",
      "122 | g_ema.convs.11.conv                | ModulatedConv2d     | 53.3 K\n",
      "123 | g_ema.convs.11.conv.modulation     | EqualLinear         | 16.4 K\n",
      "124 | g_ema.convs.11.activation          | AliasFreeActivation | 64    \n",
      "125 | g_ema.convs.12                     | AliasFreeConv       | 53.4 K\n",
      "126 | g_ema.convs.12.conv                | ModulatedConv2d     | 53.3 K\n",
      "127 | g_ema.convs.12.conv.modulation     | EqualLinear         | 16.4 K\n",
      "128 | g_ema.convs.12.activation          | AliasFreeActivation | 64    \n",
      "129 | g_ema.convs.13                     | AliasFreeConv       | 53.4 K\n",
      "130 | g_ema.convs.13.conv                | ModulatedConv2d     | 53.3 K\n",
      "131 | g_ema.convs.13.conv.modulation     | EqualLinear         | 16.4 K\n",
      "132 | g_ema.convs.13.activation          | AliasFreeActivation | 64    \n",
      "133 | g_ema.to_rgb                       | ToRGB               | 16.6 K\n",
      "134 | g_ema.to_rgb.conv                  | ModulatedConv2d     | 16.6 K\n",
      "135 | g_ema.to_rgb.conv.modulation       | EqualLinear         | 16.4 K\n",
      "136 | discriminator                      | Discriminator       | 28.9 M\n",
      "137 | discriminator.convs                | Sequential          | 22.3 M\n",
      "138 | discriminator.convs.0              | ConvLayer           | 512   \n",
      "139 | discriminator.convs.0.0            | EqualConv2d         | 384   \n",
      "140 | discriminator.convs.0.1            | FusedLeakyReLU      | 128   \n",
      "141 | discriminator.convs.1              | ResBlock            | 475 K \n",
      "142 | discriminator.convs.1.conv1        | ConvLayer           | 147 K \n",
      "143 | discriminator.convs.1.conv1.0      | EqualConv2d         | 147 K \n",
      "144 | discriminator.convs.1.conv1.1      | FusedLeakyReLU      | 128   \n",
      "145 | discriminator.convs.1.conv2        | ConvLayer           | 295 K \n",
      "146 | discriminator.convs.1.conv2.0      | Blur                | 0     \n",
      "147 | discriminator.convs.1.conv2.1      | EqualConv2d         | 294 K \n",
      "148 | discriminator.convs.1.conv2.2      | FusedLeakyReLU      | 256   \n",
      "149 | discriminator.convs.1.skip         | ConvLayer           | 32.8 K\n",
      "150 | discriminator.convs.1.skip.0       | Blur                | 0     \n",
      "151 | discriminator.convs.1.skip.1       | EqualConv2d         | 32.8 K\n",
      "152 | discriminator.convs.2              | ResBlock            | 1.9 M \n",
      "153 | discriminator.convs.2.conv1        | ConvLayer           | 590 K \n",
      "154 | discriminator.convs.2.conv1.0      | EqualConv2d         | 589 K \n",
      "155 | discriminator.convs.2.conv1.1      | FusedLeakyReLU      | 256   \n",
      "156 | discriminator.convs.2.conv2        | ConvLayer           | 1.2 M \n",
      "157 | discriminator.convs.2.conv2.0      | Blur                | 0     \n",
      "158 | discriminator.convs.2.conv2.1      | EqualConv2d         | 1.2 M \n",
      "159 | discriminator.convs.2.conv2.2      | FusedLeakyReLU      | 512   \n",
      "160 | discriminator.convs.2.skip         | ConvLayer           | 131 K \n",
      "161 | discriminator.convs.2.skip.0       | Blur                | 0     \n",
      "162 | discriminator.convs.2.skip.1       | EqualConv2d         | 131 K \n",
      "163 | discriminator.convs.3              | ResBlock            | 5.0 M \n",
      "164 | discriminator.convs.3.conv1        | ConvLayer           | 2.4 M \n",
      "165 | discriminator.convs.3.conv1.0      | EqualConv2d         | 2.4 M \n",
      "166 | discriminator.convs.3.conv1.1      | FusedLeakyReLU      | 512   \n",
      "167 | discriminator.convs.3.conv2        | ConvLayer           | 2.4 M \n",
      "168 | discriminator.convs.3.conv2.0      | Blur                | 0     \n",
      "169 | discriminator.convs.3.conv2.1      | EqualConv2d         | 2.4 M \n",
      "170 | discriminator.convs.3.conv2.2      | FusedLeakyReLU      | 512   \n",
      "171 | discriminator.convs.3.skip         | ConvLayer           | 262 K \n",
      "172 | discriminator.convs.3.skip.0       | Blur                | 0     \n",
      "173 | discriminator.convs.3.skip.1       | EqualConv2d         | 262 K \n",
      "174 | discriminator.convs.4              | ResBlock            | 5.0 M \n",
      "175 | discriminator.convs.4.conv1        | ConvLayer           | 2.4 M \n",
      "176 | discriminator.convs.4.conv1.0      | EqualConv2d         | 2.4 M \n",
      "177 | discriminator.convs.4.conv1.1      | FusedLeakyReLU      | 512   \n",
      "178 | discriminator.convs.4.conv2        | ConvLayer           | 2.4 M \n",
      "179 | discriminator.convs.4.conv2.0      | Blur                | 0     \n",
      "180 | discriminator.convs.4.conv2.1      | EqualConv2d         | 2.4 M \n",
      "181 | discriminator.convs.4.conv2.2      | FusedLeakyReLU      | 512   \n",
      "182 | discriminator.convs.4.skip         | ConvLayer           | 262 K \n",
      "183 | discriminator.convs.4.skip.0       | Blur                | 0     \n",
      "184 | discriminator.convs.4.skip.1       | EqualConv2d         | 262 K \n",
      "185 | discriminator.convs.5              | ResBlock            | 5.0 M \n",
      "186 | discriminator.convs.5.conv1        | ConvLayer           | 2.4 M \n",
      "187 | discriminator.convs.5.conv1.0      | EqualConv2d         | 2.4 M \n",
      "188 | discriminator.convs.5.conv1.1      | FusedLeakyReLU      | 512   \n",
      "189 | discriminator.convs.5.conv2        | ConvLayer           | 2.4 M \n",
      "190 | discriminator.convs.5.conv2.0      | Blur                | 0     \n",
      "191 | discriminator.convs.5.conv2.1      | EqualConv2d         | 2.4 M \n",
      "192 | discriminator.convs.5.conv2.2      | FusedLeakyReLU      | 512   \n",
      "193 | discriminator.convs.5.skip         | ConvLayer           | 262 K \n",
      "194 | discriminator.convs.5.skip.0       | Blur                | 0     \n",
      "195 | discriminator.convs.5.skip.1       | EqualConv2d         | 262 K \n",
      "196 | discriminator.convs.6              | ResBlock            | 5.0 M \n",
      "197 | discriminator.convs.6.conv1        | ConvLayer           | 2.4 M \n",
      "198 | discriminator.convs.6.conv1.0      | EqualConv2d         | 2.4 M \n",
      "199 | discriminator.convs.6.conv1.1      | FusedLeakyReLU      | 512   \n",
      "200 | discriminator.convs.6.conv2        | ConvLayer           | 2.4 M \n",
      "201 | discriminator.convs.6.conv2.0      | Blur                | 0     \n",
      "202 | discriminator.convs.6.conv2.1      | EqualConv2d         | 2.4 M \n",
      "203 | discriminator.convs.6.conv2.2      | FusedLeakyReLU      | 512   \n",
      "204 | discriminator.convs.6.skip         | ConvLayer           | 262 K \n",
      "205 | discriminator.convs.6.skip.0       | Blur                | 0     \n",
      "206 | discriminator.convs.6.skip.1       | EqualConv2d         | 262 K \n",
      "207 | discriminator.final_conv           | ConvLayer           | 2.4 M \n",
      "208 | discriminator.final_conv.0         | EqualConv2d         | 2.4 M \n",
      "209 | discriminator.final_conv.1         | FusedLeakyReLU      | 512   \n",
      "210 | discriminator.final_linear         | Sequential          | 4.2 M \n",
      "211 | discriminator.final_linear.0       | EqualLinear         | 4.2 M \n",
      "212 | discriminator.final_linear.1       | EqualLinear         | 513   \n",
      "-----------------------------------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.055   Total estimated model params size (MB)\n",
      "Training: 0it [00:00, ?it/s]\n",
      "AlignFreeGAN device: cuda:0\n",
      "\n",
      "Epoch 0:   0% 0/178 [00:00<?, ?it/s] /content/drive/MyDrive/afg-lightning-devel-arrayfire/alias-free-gan-pytorch-lightning/scripts/../src/stylegan2/op/conv2d_gradfix.py:89: UserWarning: conv2d_gradfix not supported on PyTorch 1.9.0+cu102. Falling back to torch.nn.functional.conv2d().\n",
      "  f\"conv2d_gradfix not supported on PyTorch {torch.__version__}. Falling back to torch.nn.functional.conv2d().\"\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 72, 72])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 72, 36])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 72, 72])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 72, 36])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 72, 72])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 72, 36])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 144])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 512, 144, 144])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 144, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 512, 52, 52])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 52, 104])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 104, 104])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 104, 52])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 256, 52, 52])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 52, 208])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 256, 208, 208])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 208, 104])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 256, 84, 84])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 84, 168])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 256, 168, 168])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 168, 84])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 128, 84, 84])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 84, 336])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 128, 336, 336])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 336, 168])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 128, 148, 148])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 148, 296])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 128, 296, 296])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 296, 148])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 128, 148, 148])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 148, 296])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 128, 296, 296])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 296, 148])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 64, 148, 148])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 148, 592])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 64, 592, 592])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 592, 296])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 64, 276, 276])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 276, 552])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 64, 552, 552])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 552, 276])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 64, 276, 276])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 276, 552])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 64, 552, 552])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 552, 276])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 64, 276, 276])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 276, 552])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 64, 552, 552])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 552, 276])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 128, 256, 256])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 128, 256, 256])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 256, 128, 128])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 256, 128, 128])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 64, 64])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 64, 64])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 32, 32])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 32, 32])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 16, 16])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 16, 16])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 8, 8])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 8, 8])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 72, 72])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 72, 36])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 72, 72])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 72, 36])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 72, 72])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 72, 36])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 144])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 512, 144, 144])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 144, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 512, 52, 52])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 52, 104])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 104, 104])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 104, 52])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 256, 52, 52])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 52, 208])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 256, 208, 208])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 208, 104])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 256, 84, 84])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 84, 168])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 256, 168, 168])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 168, 84])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 128, 84, 84])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 84, 336])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 128, 336, 336])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 336, 168])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 128, 148, 148])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 148, 296])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 128, 296, 296])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 296, 148])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 128, 148, 148])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 148, 296])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 128, 296, 296])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 296, 148])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 64, 148, 148])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 148, 592])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 64, 592, 592])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 592, 296])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 64, 276, 276])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 276, 552])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 64, 552, 552])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 552, 276])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 64, 276, 276])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 276, 552])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 64, 552, 552])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 552, 276])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 64, 276, 276])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 276, 552])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 64, 552, 552])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 552, 276])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 128, 256, 256])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 128, 256, 256])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 256, 128, 128])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 256, 128, 128])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 64, 64])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 64, 64])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 32, 32])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 32, 32])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 16, 16])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 16, 16])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 8, 8])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 8, 8])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 128, 256, 256])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 128, 256, 256])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 256, 128, 128])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 256, 128, 128])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 64, 64])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 64, 64])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 32, 32])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 32, 32])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 16, 16])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 16, 16])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 8, 8])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 512, 8, 8])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 72, 72])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 72, 36])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 72, 72])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 72, 36])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 72, 72])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 72, 36])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 512, 36, 36])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 36, 144])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 512, 144, 144])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 144, 72])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 512, 52, 52])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 52, 104])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 512, 104, 104])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 512, 104, 52])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 256, 52, 52])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 52, 208])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 256, 208, 208])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 208, 104])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 256, 84, 84])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 84, 168])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 256, 168, 168])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 256, 168, 84])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 128, 84, 84])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 84, 336])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 128, 336, 336])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 336, 168])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 128, 148, 148])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 148, 296])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 128, 296, 296])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 296, 148])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 128, 148, 148])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 148, 296])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 128, 296, 296])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 128, 296, 148])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 64, 148, 148])\n",
      "kernel.shape=torch.Size([1, 24])\n",
      "up=(4, 1), down=1, pad=(13, 10, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 148, 592])\n",
      "kernel.shape=torch.Size([24, 1])\n",
      "up=(1, 4), down=1, pad=(0, 0, 13, 10)\n",
      "input.shape=torch.Size([12, 64, 592, 592])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=1, down=(2, 1), pad=(5, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 592, 296])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 5, 5)\n",
      "input.shape=torch.Size([12, 64, 276, 276])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 276, 552])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 64, 552, 552])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 552, 276])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 64, 276, 276])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 276, 552])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 64, 552, 552])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 552, 276])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 64, 276, 276])\n",
      "kernel.shape=torch.Size([1, 12])\n",
      "up=(2, 1), down=1, pad=(6, 5, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 276, 552])\n",
      "kernel.shape=torch.Size([12, 1])\n",
      "up=(1, 2), down=1, pad=(0, 0, 6, 5)\n",
      "input.shape=torch.Size([12, 64, 552, 552])\n",
      "kernel.shape=torch.Size([1, 6])\n",
      "up=1, down=(2, 1), pad=(2, 2, 0, 0)\n",
      "input.shape=torch.Size([12, 64, 552, 276])\n",
      "kernel.shape=torch.Size([6, 1])\n",
      "up=1, down=(1, 2), pad=(0, 0, 2, 2)\n",
      "input.shape=torch.Size([12, 128, 256, 256])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(2, 2)\n",
      "input.shape=torch.Size([12, 128, 256, 256])\n",
      "kernel.shape=torch.Size([4, 4])\n",
      "up=1, down=1, pad=(1, 1)\n",
      "Traceback (most recent call last):\n",
      "  File \"scripts/trainer.py\", line 58, in <module>\n",
      "    cli_main()\n",
      "  File \"scripts/trainer.py\", line 55, in cli_main\n",
      "    trainer.fit(model, train_loader)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 460, in fit\n",
      "    self._run(model)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 758, in _run\n",
      "    self.dispatch()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 799, in dispatch\n",
      "    self.accelerator.start_training(self)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 96, in start_training\n",
      "    self.training_type_plugin.start_training(trainer)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 144, in start_training\n",
      "    self._results = trainer.run_stage()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 809, in run_stage\n",
      "    return self.run_train()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 871, in run_train\n",
      "    self.train_loop.run_training_epoch()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 499, in run_training_epoch\n",
      "    batch_output = self.run_training_batch(batch, batch_idx, dataloader_idx)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 738, in run_training_batch\n",
      "    self.optimizer_step(optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 442, in optimizer_step\n",
      "    using_lbfgs=is_lbfgs,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 1403, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 214, in step\n",
      "    self.__optimizer_step(*args, closure=closure, profiler_name=profiler_name, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 134, in __optimizer_step\n",
      "    trainer.accelerator.optimizer_step(optimizer, self._optimizer_idx, lambda_closure=closure, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 329, in optimizer_step\n",
      "    self.run_optimizer_step(optimizer, opt_idx, lambda_closure, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 336, in run_optimizer_step\n",
      "    self.training_type_plugin.optimizer_step(optimizer, lambda_closure=lambda_closure, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 193, in optimizer_step\n",
      "    optimizer.step(closure=lambda_closure, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\", line 66, in step\n",
      "    loss = closure()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 733, in train_step_and_backward_closure\n",
      "    split_batch, batch_idx, opt_idx, optimizer, self.trainer.hiddens\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 823, in training_step_and_backward\n",
      "    result = self.training_step(split_batch, batch_idx, opt_idx, hiddens)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 290, in training_step\n",
      "    training_step_output = self.trainer.accelerator.training_step(args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 204, in training_step\n",
      "    return self.training_type_plugin.training_step(*args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 155, in training_step\n",
      "    return self.lightning_module.training_step(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/afg-lightning-devel-arrayfire/alias-free-gan-pytorch-lightning/scripts/../src/alias_free_gan.py\", line 87, in training_step\n",
      "    fake_predict = self._get_fake_predict()\n",
      "  File \"/content/drive/MyDrive/afg-lightning-devel-arrayfire/alias-free-gan-pytorch-lightning/scripts/../src/alias_free_gan.py\", line 115, in _get_fake_predict\n",
      "    return self.discriminator(fake_img)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/content/drive/MyDrive/afg-lightning-devel-arrayfire/alias-free-gan-pytorch-lightning/scripts/../src/stylegan2/model.py\", line 691, in forward\n",
      "    out = self.convs(input)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/content/drive/MyDrive/afg-lightning-devel-arrayfire/alias-free-gan-pytorch-lightning/scripts/../src/stylegan2/model.py\", line 645, in forward\n",
      "    out = (out + skip) / math.sqrt(2)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 15.78 GiB total capacity; 12.99 GiB already allocated; 34.75 MiB free; 14.29 GiB reserved in total by PyTorch)\n",
      "Epoch 0:   0%|          | 0/178 [00:05<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "!python scripts/trainer.py \\\n",
    "    --size {mode_size} \\\n",
    "    --gpus 1 \\\n",
    "    --dataset_path {dataset_location} \\\n",
    "    --logger True \\\n",
    "    --resume_from {resume} \\\n",
    "    --max_steps 800000 \\\n",
    "    --auto_scale_batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare against original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python trainer.py \\\n",
    "#     --size 1024 \\\n",
    "#     --dataset_path \"/content/drive/MyDrive/afg-lightning-devel/alias-free-gan-pytorch/datasets/painterly-faces-256\" \\\n",
    "#     --logger True \\\n",
    "#     --weights_summary \"full\" \\\n",
    "#     --gpus 1\n",
    "\n",
    "!python train.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m07/13 23:06:35\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m\u001b[32m'ckpt'\u001b[0m: \u001b[3;35mNone\u001b[0m,                              \u001b]8;id=1626217595.1670518-402073;file://train.py\u001b\\\u001b[2mtrain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:327\u001b[0m\n",
      "                         \u001b[32m'discriminator'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__partial'\u001b[0m: \u001b[3;91mFalse\u001b[0m,                  \n",
      "                                           \u001b[32m'__target'\u001b[0m:                          \n",
      "                        \u001b[32m'stylegan2.model.Discriminator'\u001b[0m,                        \n",
      "                                           \u001b[32m'__validate'\u001b[0m: \u001b[3;92mTrue\u001b[0m,                  \n",
      "                                           \u001b[32m'channel_multiplier'\u001b[0m: \u001b[1;36m2\u001b[0m,             \n",
      "                                           \u001b[32m'size'\u001b[0m: \u001b[1;36m256\u001b[0m\u001b[1m}\u001b[0m,                        \n",
      "                         \u001b[32m'dist_url'\u001b[0m: \u001b[32m'tcp://127.0.0.1:49152'\u001b[0m,                   \n",
      "                         \u001b[32m'distributed'\u001b[0m: \u001b[3;91mFalse\u001b[0m,                                  \n",
      "                         \u001b[32m'generator'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__partial'\u001b[0m: \u001b[3;91mFalse\u001b[0m,                      \n",
      "                                       \u001b[32m'__target'\u001b[0m:                              \n",
      "                        \u001b[32m'model.Generator'\u001b[0m,                                      \n",
      "                                       \u001b[32m'__validate'\u001b[0m: \u001b[3;92mTrue\u001b[0m,                      \n",
      "                                       \u001b[32m'filter_parameters'\u001b[0m:                     \n",
      "                        \u001b[1m{\u001b[0m\u001b[32m'__partial'\u001b[0m: \u001b[3;91mFalse\u001b[0m,                                    \n",
      "                                                             \u001b[32m'__tar\u001b[0m             \n",
      "                        \u001b[32mget'\u001b[0m: \u001b[32m'model.filter_parameters'\u001b[0m,                        \n",
      "                                                             \u001b[32m'__val\u001b[0m             \n",
      "                        \u001b[32midate'\u001b[0m: \u001b[3;92mTrue\u001b[0m,                                           \n",
      "                                                             \u001b[32m'chann\u001b[0m             \n",
      "                        \u001b[32mel_base'\u001b[0m: \u001b[1;36m16384\u001b[0m,                                        \n",
      "                                                             \u001b[32m'chann\u001b[0m             \n",
      "                        \u001b[32mel_max'\u001b[0m: \u001b[1;36m512\u001b[0m,                                           \n",
      "                                                             \u001b[32m'cutof\u001b[0m             \n",
      "                        \u001b[32mf_0'\u001b[0m: \u001b[1;36m2\u001b[0m,                                                \n",
      "                                                             \u001b[32m'cutof\u001b[0m             \n",
      "                        \u001b[32mf_n'\u001b[0m: \u001b[1;36m128\u001b[0m,                                              \n",
      "                                                             \u001b[32m'n_cri\u001b[0m             \n",
      "                        \u001b[32mtical'\u001b[0m: \u001b[1;36m2\u001b[0m,                                              \n",
      "                                                             \u001b[32m'n_lay\u001b[0m             \n",
      "                        \u001b[32mer'\u001b[0m: \u001b[1;36m14\u001b[0m,                                                \n",
      "                                                             \u001b[32m'sr_ma\u001b[0m             \n",
      "                        \u001b[32mx'\u001b[0m: \u001b[1;36m256\u001b[0m,                                                \n",
      "                                                             \u001b[32m'stopb\u001b[0m             \n",
      "                        \u001b[32mand_0'\u001b[0m: \u001b[1;36m4.2870938501451725\u001b[0m,                             \n",
      "                                                             \u001b[32m'stopb\u001b[0m             \n",
      "                        \u001b[32mand_n'\u001b[0m: \u001b[1;36m157.5864849081493\u001b[0m\u001b[1m}\u001b[0m,                             \n",
      "                                       \u001b[32m'kernel_size'\u001b[0m: \u001b[1;36m3\u001b[0m,                        \n",
      "                                       \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,                            \n",
      "                                       \u001b[32m'lr_mlp'\u001b[0m: \u001b[1;36m0.01\u001b[0m,                          \n",
      "                                       \u001b[32m'margin'\u001b[0m: \u001b[1;36m10\u001b[0m,                            \n",
      "                                       \u001b[32m'n_mlp'\u001b[0m: \u001b[1;36m2\u001b[0m,                              \n",
      "                                       \u001b[32m'n_taps'\u001b[0m: \u001b[1;36m6\u001b[0m,                             \n",
      "                                       \u001b[32m'style_dim'\u001b[0m: \u001b[1;36m256\u001b[0m\u001b[1m}\u001b[0m,                       \n",
      "                         \u001b[32m'logger'\u001b[0m: \u001b[32m'rich'\u001b[0m,                                      \n",
      "                         \u001b[32m'machine_rank'\u001b[0m: \u001b[1;36m0\u001b[0m,                                     \n",
      "                         \u001b[32m'n_gpu'\u001b[0m: \u001b[1;36m1\u001b[0m,                                            \n",
      "                         \u001b[32m'n_machine'\u001b[0m: \u001b[1;36m1\u001b[0m,                                        \n",
      "                         \u001b[32m'path'\u001b[0m: \u001b[32m'/content/drive/MyDrive/afg-lightn\u001b[0m             \n",
      "                        \u001b[32ming-devel/alias-free-gan-pytorch/datasets/p\u001b[0m             \n",
      "                        \u001b[32mainterly-faces-256'\u001b[0m,                                    \n",
      "                         \u001b[32m'training'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'ada_every'\u001b[0m: \u001b[1;36m256\u001b[0m,                         \n",
      "                                      \u001b[32m'ada_length'\u001b[0m: \u001b[1;36m500000\u001b[0m,                     \n",
      "                                      \u001b[32m'ada_target'\u001b[0m: \u001b[1;36m0.6\u001b[0m,                        \n",
      "                                      \u001b[32m'augment'\u001b[0m: \u001b[3;91mFalse\u001b[0m,                         \n",
      "                                      \u001b[32m'augment_p'\u001b[0m: \u001b[1;36m0.0\u001b[0m,                         \n",
      "                                      \u001b[32m'batch'\u001b[0m: \u001b[1;36m8\u001b[0m,                               \n",
      "                                      \u001b[32m'd_reg_every'\u001b[0m: \u001b[1;36m16\u001b[0m,                        \n",
      "                                      \u001b[32m'iter'\u001b[0m: \u001b[1;36m800000\u001b[0m,                           \n",
      "                                      \u001b[32m'lr_d'\u001b[0m: \u001b[1;36m0.0025\u001b[0m,                           \n",
      "                                      \u001b[32m'lr_g'\u001b[0m: \u001b[1;36m0.003\u001b[0m,                            \n",
      "                                      \u001b[32m'n_sample'\u001b[0m: \u001b[1;36m32\u001b[0m,                           \n",
      "                                      \u001b[32m'r1'\u001b[0m: \u001b[1;36m10.0\u001b[0m,                               \n",
      "                                      \u001b[32m'size'\u001b[0m: \u001b[1;36m256\u001b[0m,                              \n",
      "                                      \u001b[32m'start_iter'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,                         \n",
      "                         \u001b[32m'wandb'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m                                        \n",
      "self.weight: torch.Size([256, 256]) on -1\n",
      "self.weight: torch.Size([256, 256]) on -1\n",
      "self.weight: torch.Size([4, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([256, 256]) on -1\n",
      "self.weight: torch.Size([256, 256]) on -1\n",
      "self.weight: torch.Size([128, 256]) on -1\n",
      "self.weight: torch.Size([128, 256]) on -1\n",
      "self.weight: torch.Size([128, 256]) on -1\n",
      "self.weight: torch.Size([64, 256]) on -1\n",
      "self.weight: torch.Size([64, 256]) on -1\n",
      "self.weight: torch.Size([64, 256]) on -1\n",
      "self.weight: torch.Size([64, 256]) on -1\n",
      "self.weight: torch.Size([256, 256]) on -1\n",
      "self.weight: torch.Size([256, 256]) on -1\n",
      "self.weight: torch.Size([4, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([512, 256]) on -1\n",
      "self.weight: torch.Size([256, 256]) on -1\n",
      "self.weight: torch.Size([256, 256]) on -1\n",
      "self.weight: torch.Size([128, 256]) on -1\n",
      "self.weight: torch.Size([128, 256]) on -1\n",
      "self.weight: torch.Size([128, 256]) on -1\n",
      "self.weight: torch.Size([64, 256]) on -1\n",
      "self.weight: torch.Size([64, 256]) on -1\n",
      "self.weight: torch.Size([64, 256]) on -1\n",
      "self.weight: torch.Size([64, 256]) on -1\n",
      "self.weight: torch.Size([512, 8192]) on -1\n",
      "self.weight: torch.Size([1, 512]) on -1\n",
      "\u001b[2;36m07/13 23:06:38\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;35mGenerator\u001b[0m\u001b[1m(\u001b[0m                                  \u001b]8;id=1626217598.3176737-465366;file://train.py\u001b\\\u001b[2mtrain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:334\u001b[0m\n",
      "                          \u001b[1m(\u001b[0mstyle\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m                                  \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mPixelNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m                          \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m                          \n",
      "                          \u001b[1m)\u001b[0m                                                     \n",
      "                          \u001b[1m(\u001b[0minput\u001b[1m)\u001b[0m: \u001b[1;35mFourierFeature\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                             \n",
      "                          \u001b[1m(\u001b[0maffine_fourier\u001b[1m)\u001b[0m: \u001b[1;35mEqualLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m                 \n",
      "                          \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m1\u001b[0m,                     \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                          \u001b[1m(\u001b[0mconvs\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m                                  \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                 \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m              \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                 \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m              \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                 \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m              \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                 \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m              \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                 \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m              \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                 \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m256\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m              \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                 \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m256\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m              \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                 \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m              \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                 \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m              \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                 \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m              \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m                \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m                \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeConv\u001b[0m\u001b[1m(\u001b[0m                                \n",
      "                              \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m64\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m                \n",
      "                              \u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mAliasFreeActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m               \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                          \u001b[1m)\u001b[0m                                                     \n",
      "                          \u001b[1m(\u001b[0mto_rgb\u001b[1m)\u001b[0m: \u001b[1;35mToRGB\u001b[0m\u001b[1m(\u001b[0m                                      \n",
      "                            \u001b[1m(\u001b[0mconv\u001b[1m)\u001b[0m: \u001b[1;35mModulatedConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                   \n",
      "                          \u001b[1m)\u001b[0m                                                     \n",
      "                        \u001b[1m)\u001b[0m                                                       \n",
      "\u001b[2;36m              \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;35mDiscriminator\u001b[0m\u001b[1m(\u001b[0m                              \u001b]8;id=1626217598.336328-421225;file://train.py\u001b\\\u001b[2mtrain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:335\u001b[0m\n",
      "                          \u001b[1m(\u001b[0mconvs\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m                                  \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                                     \n",
      "                              \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1;36m1\u001b[0m,             \n",
      "                        \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                              \n",
      "                              \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                             \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResBlock\u001b[0m\u001b[1m(\u001b[0m                                      \n",
      "                              \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m256\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mskip\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                                \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m256\u001b[0m, \u001b[1;36m1\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResBlock\u001b[0m\u001b[1m(\u001b[0m                                      \n",
      "                              \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m256\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mskip\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                                \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m1\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResBlock\u001b[0m\u001b[1m(\u001b[0m                                      \n",
      "                              \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mskip\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                                \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m1\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResBlock\u001b[0m\u001b[1m(\u001b[0m                                      \n",
      "                              \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mskip\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                                \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m1\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResBlock\u001b[0m\u001b[1m(\u001b[0m                                      \n",
      "                              \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mskip\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                                \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m1\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mResBlock\u001b[0m\u001b[1m(\u001b[0m                                      \n",
      "                              \u001b[1m(\u001b[0mconv1\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mconv2\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                               \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                           \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                              \u001b[1m(\u001b[0mskip\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                                \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlur\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                     \n",
      "                                \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m1\u001b[0m,                   \n",
      "                        \u001b[33mstride\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mpadding\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m                                    \n",
      "                              \u001b[1m)\u001b[0m                                                 \n",
      "                            \u001b[1m)\u001b[0m                                                   \n",
      "                          \u001b[1m)\u001b[0m                                                     \n",
      "                          \u001b[1m(\u001b[0mfinal_conv\u001b[1m)\u001b[0m: \u001b[1;35mConvLayer\u001b[0m\u001b[1m(\u001b[0m                              \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualConv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m513\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[33mstride\u001b[0m=\u001b[1;36m1\u001b[0m,             \n",
      "                        \u001b[33mpadding\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                                              \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mFusedLeakyReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                               \n",
      "                          \u001b[1m)\u001b[0m                                                     \n",
      "                          \u001b[1m(\u001b[0mfinal_linear\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m                           \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m8192\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m                         \n",
      "                            \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEqualLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m                            \n",
      "                          \u001b[1m)\u001b[0m                                                     \n",
      "                        \u001b[1m)\u001b[0m                                                       \n",
      "  0% 0/800000 [00:00<?, ?it/s]0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "before self.weight: torch.Size([256, 256]) on 0\n",
      "after self.weight: torch.Size([256, 256]) on 0\n",
      "before temp: torch.Size([256, 256]) on 0\n",
      "after temp: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "before self.weight: torch.Size([256, 256]) on 0\n",
      "after self.weight: torch.Size([256, 256]) on 0\n",
      "before temp: torch.Size([256, 256]) on 0\n",
      "after temp: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([4, 256]) on 0\n",
      "/content/drive/MyDrive/afg-lightning-devel/alias-free-gan-pytorch/stylegan2/op/conv2d_gradfix.py:89: UserWarning: conv2d_gradfix not supported on PyTorch 1.9.0+cu102. Falling back to torch.nn.functional.conv2d().\n",
      "  f\"conv2d_gradfix not supported on PyTorch {torch.__version__}. Falling back to torch.nn.functional.conv2d().\"\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 8192]) on 0\n",
      "before self.weight: torch.Size([512, 8192]) on 0\n",
      "after self.weight: torch.Size([512, 8192]) on 0\n",
      "before temp: torch.Size([512, 8192]) on 0\n",
      "after temp: torch.Size([512, 8192]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([1, 512]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 8192]) on 0\n",
      "before self.weight: torch.Size([512, 8192]) on 0\n",
      "after self.weight: torch.Size([512, 8192]) on 0\n",
      "before temp: torch.Size([512, 8192]) on 0\n",
      "after temp: torch.Size([512, 8192]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([1, 512]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 8192]) on 0\n",
      "before self.weight: torch.Size([512, 8192]) on 0\n",
      "after self.weight: torch.Size([512, 8192]) on 0\n",
      "before temp: torch.Size([512, 8192]) on 0\n",
      "after temp: torch.Size([512, 8192]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([1, 512]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "before self.weight: torch.Size([256, 256]) on 0\n",
      "after self.weight: torch.Size([256, 256]) on 0\n",
      "before temp: torch.Size([256, 256]) on 0\n",
      "after temp: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "before self.weight: torch.Size([256, 256]) on 0\n",
      "after self.weight: torch.Size([256, 256]) on 0\n",
      "before temp: torch.Size([256, 256]) on 0\n",
      "after temp: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([4, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 8192]) on 0\n",
      "before self.weight: torch.Size([512, 8192]) on 0\n",
      "after self.weight: torch.Size([512, 8192]) on 0\n",
      "before temp: torch.Size([512, 8192]) on 0\n",
      "after temp: torch.Size([512, 8192]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([1, 512]) on 0\n",
      "d: 1.4022; g: 0.5519; r1: 0.0002; augment: 0.0000:   0% 0/800000 [00:02<?, ?it/s]0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "before self.weight: torch.Size([256, 256]) on 0\n",
      "after self.weight: torch.Size([256, 256]) on 0\n",
      "before temp: torch.Size([256, 256]) on 0\n",
      "after temp: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "before self.weight: torch.Size([256, 256]) on 0\n",
      "after self.weight: torch.Size([256, 256]) on 0\n",
      "before temp: torch.Size([256, 256]) on 0\n",
      "after temp: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([4, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "d: 1.4022; g: 0.5519; r1: 0.0002; augment: 0.0000:   0% 1/800000 [00:15<3345:07:14, 15.05s/it]0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "before self.weight: torch.Size([256, 256]) on 0\n",
      "after self.weight: torch.Size([256, 256]) on 0\n",
      "before temp: torch.Size([256, 256]) on 0\n",
      "after temp: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "before self.weight: torch.Size([256, 256]) on 0\n",
      "after self.weight: torch.Size([256, 256]) on 0\n",
      "before temp: torch.Size([256, 256]) on 0\n",
      "after temp: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([4, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([256, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([128, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([64, 256]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 8192]) on 0\n",
      "before self.weight: torch.Size([512, 8192]) on 0\n",
      "after self.weight: torch.Size([512, 8192]) on 0\n",
      "before temp: torch.Size([512, 8192]) on 0\n",
      "after temp: torch.Size([512, 8192]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([1, 512]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([512, 8192]) on 0\n",
      "before self.weight: torch.Size([512, 8192]) on 0\n",
      "after self.weight: torch.Size([512, 8192]) on 0\n",
      "before temp: torch.Size([512, 8192]) on 0\n",
      "after temp: torch.Size([512, 8192]) on 0\n",
      "0\n",
      "EqualLinear.forward() self.device: cpu\n",
      "self.weight: torch.Size([1, 512]) on 0\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 406, in <module>\n",
      "    main, conf.n_gpu, conf.n_machine, conf.machine_rank, conf.dist_url, args=(conf,)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorfn/distributed/launch.py\", line 49, in launch\n",
      "    fn(*args)\n",
      "  File \"train.py\", line 399, in main\n",
      "    train(conf, loader, generator, discriminator, g_optim, d_optim, g_ema, device)\n",
      "  File \"train.py\", line 215, in train\n",
      "    d_loss.backward()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 255, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 149, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "RuntimeError: Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward.\n",
      "d: 1.4022; g: 0.5519; r1: 0.0002; augment: 0.0000:   0% 1/800000 [00:15<3489:14:39, 15.70s/it]\n"
     ]
    }
   ],
   "source": [
    "!python train.py --n_gpu 1 --conf /content/drive/MyDrive/afg-lightning-devel/alias-free-gan-pytorch/config/config-t-256.jsonnet training.batch=8 path=\"/content/drive/MyDrive/afg-lightning-devel/alias-free-gan-pytorch/datasets/painterly-faces-256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}