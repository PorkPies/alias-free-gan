{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/alias-free-devel-gen/alias-free-gan\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/alias-free-devel-gen/alias-free-gan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.4.0-py3-none-any.whl (913 kB)\n",
      "\u001b[K     |████████████████████████████████| 913 kB 14.0 MB/s \n",
      "\u001b[?25hCollecting pytorch-lightning-bolts\n",
      "  Downloading pytorch_lightning_bolts-0.3.2-py3-none-any.whl (253 kB)\n",
      "\u001b[K     |████████████████████████████████| 253 kB 24.8 MB/s \n",
      "\u001b[?25hCollecting wandb\n",
      "  Downloading wandb-0.11.1-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 59.3 MB/s \n",
      "\u001b[?25hCollecting ninja\n",
      "  Downloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 78.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 68.2 MB/s \n",
      "\u001b[?25hCollecting pyhocon\n",
      "  Downloading pyhocon-0.3.58.tar.gz (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 65.5 MB/s \n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.1 MB 1.2 MB/s \n",
      "\u001b[?25hCollecting torchmetrics>=0.4.0\n",
      "  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\n",
      "\u001b[K     |████████████████████████████████| 234 kB 77.7 MB/s \n",
      "\u001b[?25hCollecting future>=0.17.1\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 60.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 69.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.9.0+cu102)\n",
      "Collecting PyYAML>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 47.3 MB/s \n",
      "\u001b[?25hCollecting tensorboard!=2.5.0,>=2.2.0\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 45.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.7.4.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.0)\n",
      "Collecting pyDeprecate==0.3.1\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 48.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.17.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.36.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.32.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (57.2.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.34.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.6.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
      "Collecting graphql-core>=2.3.0\n",
      "  Downloading graphql_core-3.1.5-py3-none-any.whl (188 kB)\n",
      "\u001b[K     |████████████████████████████████| 188 kB 66.8 MB/s \n",
      "\u001b[?25hCollecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 61.9 MB/s \n",
      "\u001b[?25hCollecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "\u001b[K     |████████████████████████████████| 170 kB 70.5 MB/s \n",
      "\u001b[?25hCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.10.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.4.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest) (0.7.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (8.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (21.2.0)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 66.3 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 60.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.5.0)\n",
      "Building wheels for collected packages: future, pyhocon, pathtools\n",
      "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=301f5d7208e9f06475685e1e03d4557acaa5052eeeaf865ea178a31820021e10\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for pyhocon (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyhocon: filename=pyhocon-0.3.58-py3-none-any.whl size=19889 sha256=f66f523c717796eb5311d9aa8c50c6b446ab4c61733f03b65057ad7af16fb78c\n",
      "  Stored in directory: /root/.cache/pip/wheels/cb/20/f9/ff360765ce6f9fc078d6599c10a8f36496e5b5011a29df1ae3\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=df95ff686f3c6e5153740a34de8d054215feee5d062c9aa6b5f30f749fced922\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "Successfully built future pyhocon pathtools\n",
      "Installing collected packages: multidict, yarl, async-timeout, smmap, fsspec, aiohttp, torchmetrics, tensorboard, PyYAML, pyDeprecate, gitdb, future, shortuuid, sentry-sdk, pytorch-lightning, pathtools, graphql-core, GitPython, docker-pycreds, configparser, wandb, pytorch-lightning-bolts, pyhocon, pydantic, opencv-python-headless, ninja\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 0.16.0\n",
      "    Uninstalling future-0.16.0:\n",
      "      Successfully uninstalled future-0.16.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.4.1 which is incompatible.\u001b[0m\n",
      "Successfully installed GitPython-3.1.18 PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 configparser-5.0.2 docker-pycreds-0.4.0 fsspec-2021.7.0 future-0.18.2 gitdb-4.0.7 graphql-core-3.1.5 multidict-5.1.0 ninja-1.10.2 opencv-python-headless-4.5.3.56 pathtools-0.1.2 pyDeprecate-0.3.1 pydantic-1.8.2 pyhocon-0.3.58 pytorch-lightning-1.4.0 pytorch-lightning-bolts-0.3.2 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 tensorboard-2.4.1 torchmetrics-0.4.1 wandb-0.11.1 yarl-1.6.3\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
      "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (0.99)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.23)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.2.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
      "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-1sdh9_fb/pytorch_3fa3e2660d184d60a412ddee7e167caa/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-1sdh9_fb/pytorch_3fa3e2660d184d60a412ddee7e167caa/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-wstftbvt/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/pytorch Check the logs for full command output.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python install.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Alias-Free GAN version: 1.0.0\n",
      "usage: generate_images.py [-h] --load_model LOAD_MODEL --outdir OUTDIR\n",
      "                          [--model_arch MODEL_ARCH] [--seed_start SEED_START]\n",
      "                          [--seed_stop SEED_STOP] [--trunc TRUNC] --space\n",
      "                          SPACE --size SIZE\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "Generate Script:\n",
      "  --load_model LOAD_MODEL\n",
      "                        Load a model checkpoint to use for generating content.\n",
      "  --outdir OUTDIR       Where to save the output images\n",
      "  --model_arch MODEL_ARCH\n",
      "                        The model architecture of the model to be loaded.\n",
      "                        (default: alias-free-rosinality-v1)\n",
      "  --seed_start SEED_START\n",
      "                        Start range for seed values. (default: 0)\n",
      "  --seed_stop SEED_STOP\n",
      "                        Stop range for seed values. Is inclusive. (default:\n",
      "                        99)\n",
      "  --trunc TRUNC         Truncation psi (default: 0.75)\n",
      "  --space SPACE         latent space 'w' or 'z' (default: z)\n",
      "\n",
      "AliasFreeGenerator:\n",
      "  --size SIZE           Pixel dimension of model. Must be 256, 512, or 1024.\n",
      "                        Required!\n"
     ]
    }
   ],
   "source": [
    "!python scripts/generate_images.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Alias-Free GAN version: 1.0.0\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2021-07-31 00:46:51.332637: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 17.3 M\n",
      "1 | g_ema         | Generator     | 17.3 M\n",
      "2 | discriminator | Discriminator | 28.9 M\n",
      "------------------------------------------------\n",
      "63.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "63.5 M    Total params\n",
      "253.864   Total estimated model params size (MB)\n",
      "Loading Model from: /content/drive/MyDrive/alias-free-models/painterly-faces/v2-cp10/painterly-faces-v2-cp10.pt\n",
      "\n",
      "Generating image for seed 0 at truncation 0.750000 saving to ./gen-test2/seed0000.png\n",
      "Generating image for seed 1 at truncation 0.750000 saving to ./gen-test2/seed0001.png\n",
      "Generating image for seed 2 at truncation 0.750000 saving to ./gen-test2/seed0002.png\n",
      "Generating image for seed 3 at truncation 0.750000 saving to ./gen-test2/seed0003.png\n",
      "Generating image for seed 4 at truncation 0.750000 saving to ./gen-test2/seed0004.png\n",
      "Generating image for seed 5 at truncation 0.750000 saving to ./gen-test2/seed0005.png\n",
      "Generating image for seed 6 at truncation 0.750000 saving to ./gen-test2/seed0006.png\n",
      "Generating image for seed 7 at truncation 0.750000 saving to ./gen-test2/seed0007.png\n",
      "Generating image for seed 8 at truncation 0.750000 saving to ./gen-test2/seed0008.png\n",
      "Generating image for seed 9 at truncation 0.750000 saving to ./gen-test2/seed0009.png\n",
      "Generating image for seed 10 at truncation 0.750000 saving to ./gen-test2/seed0010.png\n",
      "Generating image for seed 11 at truncation 0.750000 saving to ./gen-test2/seed0011.png\n",
      "Generating image for seed 12 at truncation 0.750000 saving to ./gen-test2/seed0012.png\n",
      "Generating image for seed 13 at truncation 0.750000 saving to ./gen-test2/seed0013.png\n"
     ]
    }
   ],
   "source": [
    "!python scripts/generate_images.py --size 256 --load_mode /content/drive/MyDrive/alias-free-models/painterly-faces/v2-cp10/painterly-faces-v2-cp10.pt --outdir './gen-test2' --space 'z' --batch 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: prepare_dataset.py [-h] [--size SIZE] [--n_worker N_WORKER]\n",
      "                          [--resample RESAMPLE]\n",
      "                          path out\n",
      "\n",
      "Preprocess images for model training\n",
      "\n",
      "positional arguments:\n",
      "  path                 Path to the image dataset.\n",
      "  out                  Filename of the result lmdb dataset.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help           show this help message and exit\n",
      "  --size SIZE          Resolutions of images for the dataset. (default:\n",
      "                       256,512,1024)\n",
      "  --n_worker N_WORKER  Number of workers for preparing dataset. (default: 2)\n",
      "  --resample RESAMPLE  Resampling methods for resizing images. 'lanczos' or\n",
      "                       'bilinear' (default: lanczos)\n"
     ]
    }
   ],
   "source": [
    "!python scripts/prepare_dataset.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconverted_dataset = '/content/drive/MyDrive/dataset-creation/painterly-faces-v2'\n",
    "out_path = '/content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-512'\n",
    "dataset_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make dataset of image sizes: 512\n",
      "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "1158it [04:46,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "!python scripts/convert_dataset.py --size {dataset_size} {unconverted_dataset} {out_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/trainer.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 256\n",
    "dataset_location = '/content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-256'\n",
    "resume = 'rosinality-ffhq-800k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Alias-Free GAN version: 1.0.0\n",
      "\n",
      "\n",
      "Licence and compensation information for rosinality-ffhq-800k pretrained model: test information\n",
      "\n",
      "\n",
      "Dataset path: /content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-256\n",
      "Initialized MultiResolutionDataset dataset with 1158 images\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2021-07-28 10:17:29.993491: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 17.3 M\n",
      "1 | g_ema         | Generator     | 17.3 M\n",
      "2 | discriminator | Discriminator | 28.9 M\n",
      "------------------------------------------------\n",
      "63.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "63.5 M    Total params\n",
      "253.864   Total estimated model params size (MB)\n",
      "Training: -1it [00:00, ?it/s]\n",
      "\n",
      "Resuming from: /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/scripts/../pretrained/rosinality-ffhq-800k.pt\n",
      "\n",
      "AlignFreeGAN device: cuda:0\n",
      "\n",
      "\n",
      "Saving z-samples out ...\n",
      "Epoch 0:   0% 0/144 [00:00<?, ?it/s] /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/scripts/../src/stylegan2/op/conv2d_gradfix.py:89: UserWarning: conv2d_gradfix not supported on PyTorch 1.9.0+cu102. Falling back to torch.nn.functional.conv2d().\n",
      "  f\"conv2d_gradfix not supported on PyTorch {torch.__version__}. Falling back to torch.nn.functional.conv2d().\"\n",
      "Epoch 0: 100% 144/144 [03:58<00:00,  1.65s/it, loss=1.7, v_num=87] [LightningAdam(groups=[{'amsgrad': False, 'betas': (0, 0.99), 'eps': 1e-08, 'lr': 0.002, 'weight_decay': 0}]), LightningAdam(groups=[{'amsgrad': False, 'betas': (0.0, 0.9905854573074332), 'eps': 1e-08, 'lr': 0.001882352941, 'weight_decay': 0}])]\n",
      "Epoch 1:   0% 0/144 [00:12<?, ?it/s, loss=1.7, v_num=87]"
     ]
    }
   ],
   "source": [
    "!python scripts/trainer.py \\\n",
    "    --size {model_size} \\\n",
    "    --gpus 1 \\\n",
    "    --dataset_path {dataset_location} \\\n",
    "    --resume_from {resume} \\\n",
    "    --logger True \\\n",
    "    --max_steps 800000 \\\n",
    "    --batch 8 \\\n",
    "    --n_samples 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}