{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python install.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: prepare_dataset.py [-h] [--size SIZE] [--n_worker N_WORKER]\n",
      "                          [--resample RESAMPLE]\n",
      "                          path out\n",
      "\n",
      "Preprocess images for model training\n",
      "\n",
      "positional arguments:\n",
      "  path                 Path to the image dataset.\n",
      "  out                  Filename of the result lmdb dataset.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help           show this help message and exit\n",
      "  --size SIZE          Resolutions of images for the dataset. (default:\n",
      "                       256,512,1024)\n",
      "  --n_worker N_WORKER  Number of workers for preparing dataset. (default: 2)\n",
      "  --resample RESAMPLE  Resampling methods for resizing images. 'lanczos' or\n",
      "                       'bilinear' (default: lanczos)\n"
     ]
    }
   ],
   "source": [
    "!python scripts/prepare_dataset.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconverted_dataset = '/content/drive/MyDrive/dataset-creation/painterly-faces-v2'\n",
    "out_path = '/content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-512'\n",
    "dataset_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make dataset of image sizes: 512\n",
      "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "1158it [04:46,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "!python scripts/convert_dataset.py --size {dataset_size} {unconverted_dataset} {out_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/trainer.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 512\n",
    "dataset_location = '/content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-512'\n",
    "resume = 'rosinality-ffhq-280000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-512\n",
      "Initialized MultiResolutionDataset dataset with 1158 images\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "{'style_dim': 512, 'n_mlp': 2, 'kernel_size': 3, 'n_taps': 6, 'filter_parameters': {'cutoffs': [2.0, 2.996614153753363, 4.489848193237492, 6.727171322029716, 10.079368399158984, 15.101989002907096, 22.627416997969522, 33.90281901949746, 50.79683366298237, 76.10925536017415, 114.03503592196346, 170.85950133376437, 256.0, 256.0], 'stopbands': [4.2870938501451725, 6.133313378678402, 8.774599837557007, 12.553345566348012, 17.95939277294997, 25.69353221962805, 36.758347359905116, 52.58818013349059, 75.23506600215094, 107.63474115247546, 153.98720461851096, 220.30116793454846, 315.1729698162986, 315.1729698162986], 'srs': [16, 16, 32, 32, 64, 64, 128, 128, 256, 256, 256, 256, 256, 256], 'band_halfs': [6.0, 5.003385846246637, 11.510151806762508, 9.272828677970285, 21.920631600841016, 16.898010997092904, 41.37258300203048, 30.097180980502543, 77.20316633701762, 51.890744639825854, 39.9521686965475, 49.44166660078409, 59.172969816298576, 59.172969816298576], 'channels': [512, 512, 512, 512, 256, 256, 128, 128, 64, 64, 64, 64, 64, 64]}}\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2021-07-26 23:31:08.040950: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 14.6 M\n",
      "1 | g_ema         | Generator     | 14.6 M\n",
      "2 | discriminator | Discriminator | 29.0 M\n",
      "------------------------------------------------\n",
      "58.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.769   Total estimated model params size (MB)\n",
      "Training: 0it [00:00, ?it/s]\n",
      "\n",
      "Resuming from: /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/scripts/../pretrained/rosinality-ffhq-280000.pt\n",
      "\n",
      "{'n_gpu': 4, 'n_machine': 1, 'machine_rank': 0, 'dist_url': 'tcp://127.0.0.1:49152', 'distributed': True, 'ckpt': 'checkpoint/250000.pt', 'generator': {'__target': 'model.Generator', '__validate': True, '__partial': False, 'filter_parameters': {'__target': 'model.filter_parameters', '__validate': True, '__partial': False, 'channel_base': 16384, 'channel_max': 512, 'cutoff_0': 2, 'cutoff_n': 128, 'n_critical': 2, 'n_layer': 14, 'sr_max': 256, 'stopband_0': 4.2870938501451725, 'stopband_n': 157.5864849081493}, 'kernel_size': 3, 'lr_mlp': 0.01, 'margin': 10, 'n_mlp': 2, 'n_taps': 6, 'style_dim': 512}, 'discriminator': {'__target': 'stylegan2.model.Discriminator', '__validate': True, '__partial': False, 'channel_multiplier': 2, 'size': 256}, 'training': {'size': 256, 'iter': 800000, 'batch': 8, 'n_sample': 32, 'r1': 10.0, 'd_reg_every': 16, 'lr_g': 0.003, 'lr_d': 0.0025, 'augment': False, 'augment_p': 0.0, 'ada_target': 0.6, 'ada_length': 500000, 'ada_every': 256, 'start_iter': 250000}, 'path': '../stylegan2-pytorch/ffhq.lmdb', 'wandb': True, 'logger': 'rich'}\n",
      "Traceback (most recent call last):\n",
      "  File \"scripts/trainer.py\", line 84, in <module>\n",
      "    cli_main()\n",
      "  File \"scripts/trainer.py\", line 81, in cli_main\n",
      "    trainer.fit(model, train_loader)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 460, in fit\n",
      "    self._run(model)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 758, in _run\n",
      "    self.dispatch()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 799, in dispatch\n",
      "    self.accelerator.start_training(self)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 96, in start_training\n",
      "    self.training_type_plugin.start_training(trainer)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 144, in start_training\n",
      "    self._results = trainer.run_stage()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 809, in run_stage\n",
      "    return self.run_train()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 857, in run_train\n",
      "    self.train_loop.on_train_start()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 101, in on_train_start\n",
      "    self.trainer.call_hook(\"on_train_start\")\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1235, in call_hook\n",
      "    output = hook_fx(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/scripts/../src/alias_free_gan.py\", line 94, in on_train_start\n",
      "    self.load_checkpoint(self.resume_path)\n",
      "  File \"/content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/scripts/../src/alias_free_gan.py\", line 236, in load_checkpoint\n",
      "    self.generator.load_state_dict(checkpoint[\"g\"])\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1407, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for convs.2.activation.upsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "\tsize mismatch for convs.2.activation.downsample_filter: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.3.activation.upsample_filter: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.3.activation.downsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "\tsize mismatch for convs.4.conv.weight: copying a param with shape torch.Size([1, 512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 256, 512, 3, 3]).\n",
      "\tsize mismatch for convs.4.activation.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for convs.4.activation.upsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "\tsize mismatch for convs.4.activation.downsample_filter: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.5.conv.weight: copying a param with shape torch.Size([1, 256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 256, 256, 3, 3]).\n",
      "\tsize mismatch for convs.5.conv.modulation.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n",
      "\tsize mismatch for convs.5.conv.modulation.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for convs.5.activation.upsample_filter: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.5.activation.downsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "\tsize mismatch for convs.6.conv.weight: copying a param with shape torch.Size([1, 256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 128, 256, 3, 3]).\n",
      "\tsize mismatch for convs.6.activation.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for convs.6.activation.upsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "\tsize mismatch for convs.6.activation.downsample_filter: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.7.conv.weight: copying a param with shape torch.Size([1, 128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 128, 128, 3, 3]).\n",
      "\tsize mismatch for convs.7.conv.modulation.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([128, 512]).\n",
      "\tsize mismatch for convs.7.conv.modulation.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for convs.7.activation.upsample_filter: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.7.activation.downsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "\tsize mismatch for convs.8.conv.weight: copying a param with shape torch.Size([1, 128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 64, 128, 3, 3]).\n",
      "\tsize mismatch for convs.8.activation.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for convs.8.activation.upsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "\tsize mismatch for convs.8.activation.downsample_filter: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.9.conv.weight: copying a param with shape torch.Size([1, 128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 64, 64, 3, 3]).\n",
      "\tsize mismatch for convs.9.conv.modulation.weight: copying a param with shape torch.Size([128, 512]) from checkpoint, the shape in current model is torch.Size([64, 512]).\n",
      "\tsize mismatch for convs.9.conv.modulation.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for convs.9.activation.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for convs.10.conv.weight: copying a param with shape torch.Size([1, 64, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 64, 64, 3, 3]).\n",
      "\tsize mismatch for convs.10.conv.modulation.weight: copying a param with shape torch.Size([128, 512]) from checkpoint, the shape in current model is torch.Size([64, 512]).\n",
      "\tsize mismatch for convs.10.conv.modulation.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for convs.10.activation.upsample_filter: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.10.activation.downsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "Training: 0it [00:01, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "!python scripts/trainer.py \\\n",
    "    --size {model_size} \\\n",
    "    --gpus 1 \\\n",
    "    --dataset_path {dataset_location} \\\n",
    "    --resume_from {resume} \\\n",
    "    --logger True \\\n",
    "    --max_steps 800000 \\\n",
    "    --batch 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}