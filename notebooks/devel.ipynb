{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python install.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: prepare_dataset.py [-h] [--size SIZE] [--n_worker N_WORKER]\n",
      "                          [--resample RESAMPLE]\n",
      "                          path out\n",
      "\n",
      "Preprocess images for model training\n",
      "\n",
      "positional arguments:\n",
      "  path                 Path to the image dataset.\n",
      "  out                  Filename of the result lmdb dataset.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help           show this help message and exit\n",
      "  --size SIZE          Resolutions of images for the dataset. (default:\n",
      "                       256,512,1024)\n",
      "  --n_worker N_WORKER  Number of workers for preparing dataset. (default: 2)\n",
      "  --resample RESAMPLE  Resampling methods for resizing images. 'lanczos' or\n",
      "                       'bilinear' (default: lanczos)\n"
     ]
    }
   ],
   "source": [
    "!python scripts/prepare_dataset.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconverted_dataset = '/content/drive/MyDrive/dataset-creation/painterly-faces-v2'\n",
    "out_path = '/content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-512'\n",
    "dataset_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make dataset of image sizes: 512\n",
      "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "1158it [04:46,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "!python scripts/convert_dataset.py --size {dataset_size} {unconverted_dataset} {out_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/trainer.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 256\n",
    "dataset_location = '/content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-256'\n",
    "resume = 'rosinality-ffhq-800k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Alias-Free GAN version: 1.0.0\n",
      "\n",
      "\n",
      "Licence and compensation information for rosinality-ffhq-800k pretrained model: test information\n",
      "\n",
      "\n",
      "Dataset path: /content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-256\n",
      "Initialized MultiResolutionDataset dataset with 1158 images\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2021-07-28 10:17:29.993491: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 17.3 M\n",
      "1 | g_ema         | Generator     | 17.3 M\n",
      "2 | discriminator | Discriminator | 28.9 M\n",
      "------------------------------------------------\n",
      "63.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "63.5 M    Total params\n",
      "253.864   Total estimated model params size (MB)\n",
      "Training: -1it [00:00, ?it/s]\n",
      "\n",
      "Resuming from: /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/scripts/../pretrained/rosinality-ffhq-800k.pt\n",
      "\n",
      "AlignFreeGAN device: cuda:0\n",
      "\n",
      "\n",
      "Saving z-samples out ...\n",
      "Epoch 0:   0% 0/144 [00:00<?, ?it/s] /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/scripts/../src/stylegan2/op/conv2d_gradfix.py:89: UserWarning: conv2d_gradfix not supported on PyTorch 1.9.0+cu102. Falling back to torch.nn.functional.conv2d().\n",
      "  f\"conv2d_gradfix not supported on PyTorch {torch.__version__}. Falling back to torch.nn.functional.conv2d().\"\n",
      "Epoch 0: 100% 144/144 [03:58<00:00,  1.65s/it, loss=1.7, v_num=87] [LightningAdam(groups=[{'amsgrad': False, 'betas': (0, 0.99), 'eps': 1e-08, 'lr': 0.002, 'weight_decay': 0}]), LightningAdam(groups=[{'amsgrad': False, 'betas': (0.0, 0.9905854573074332), 'eps': 1e-08, 'lr': 0.001882352941, 'weight_decay': 0}])]\n",
      "Epoch 1:   0% 0/144 [00:12<?, ?it/s, loss=1.7, v_num=87]"
     ]
    }
   ],
   "source": [
    "!python scripts/trainer.py \\\n",
    "    --size {model_size} \\\n",
    "    --gpus 1 \\\n",
    "    --dataset_path {dataset_location} \\\n",
    "    --resume_from {resume} \\\n",
    "    --logger True \\\n",
    "    --max_steps 800000 \\\n",
    "    --batch 8 \\\n",
    "    --n_samples 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}