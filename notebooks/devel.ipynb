{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\n",
      "\u001b[K     |████████████████████████████████| 813 kB 9.5 MB/s \n",
      "\u001b[?25hCollecting pytorch-lightning-bolts\n",
      "  Downloading pytorch_lightning_bolts-0.3.2-py3-none-any.whl (253 kB)\n",
      "\u001b[K     |████████████████████████████████| 253 kB 79.4 MB/s \n",
      "\u001b[?25hCollecting wandb\n",
      "  Downloading wandb-0.11.0-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 56.7 MB/s \n",
      "\u001b[?25hCollecting ninja\n",
      "  Downloading ninja-1.10.0.post3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 77.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 30.2 MB/s \n",
      "\u001b[?25hCollecting pyhocon\n",
      "  Downloading pyhocon-0.3.58.tar.gz (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 71.8 MB/s \n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.1 MB 81 kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
      "Collecting torchmetrics>=0.2.0\n",
      "  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\n",
      "\u001b[K     |████████████████████████████████| 234 kB 59.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.9.0+cu102)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 70.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (7.1.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.0)\n",
      "Collecting tensorboard!=2.5.0,>=2.2.0\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 45.9 MB/s \n",
      "\u001b[?25hCollecting PyYAML<=5.4.1,>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 57.2 MB/s \n",
      "\u001b[?25hCollecting future>=0.17.1\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 49.3 MB/s \n",
      "\u001b[?25hCollecting pyDeprecate==0.3.0\n",
      "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 55.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.34.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (57.2.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.32.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.12.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.17.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.6.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.10.33-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 59.6 MB/s \n",
      "\u001b[?25hCollecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 7.7 MB/s \n",
      "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
      "  Downloading sentry_sdk-1.3.0-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 66.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "\u001b[K     |████████████████████████████████| 170 kB 81.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
      "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (21.2.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.10.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (8.8.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest) (0.7.1)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 72.2 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 57.4 MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.5.0)\n",
      "Building wheels for collected packages: future, subprocess32, pyhocon, pathtools\n",
      "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=429012e23d30e8eeeffb8a1b9dbc8034b1cab7f978b278dc297e2ae682ff4797\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=37d39656d6a68e70b393bfd4ab5b210c9402dd16d3c577ec68631d88aef35134\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
      "  Building wheel for pyhocon (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyhocon: filename=pyhocon-0.3.58-py3-none-any.whl size=19889 sha256=fc452d294b4184c7495cd718113ba7ac7225cea1c9a4cab68d25963e700d0e50\n",
      "  Stored in directory: /root/.cache/pip/wheels/cb/20/f9/ff360765ce6f9fc078d6599c10a8f36496e5b5011a29df1ae3\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=6aca5c4bc071f0d1a12b39d365e24153e17c26ec41907da6ba76d1fc641a92ff\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "Successfully built future subprocess32 pyhocon pathtools\n",
      "Installing collected packages: multidict, yarl, async-timeout, smmap, fsspec, aiohttp, torchmetrics, tensorboard, PyYAML, pyDeprecate, gitdb, future, subprocess32, shortuuid, sentry-sdk, pytorch-lightning, pathtools, GitPython, docker-pycreds, configparser, wandb, pytorch-lightning-bolts, pyhocon, pydantic, opencv-python-headless, ninja\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 0.16.0\n",
      "    Uninstalling future-0.16.0:\n",
      "      Successfully uninstalled future-0.16.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.4.1 which is incompatible.\u001b[0m\n",
      "Successfully installed GitPython-3.1.18 PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 configparser-5.0.2 docker-pycreds-0.4.0 fsspec-2021.7.0 future-0.18.2 gitdb-4.0.7 multidict-5.1.0 ninja-1.10.0.post3 opencv-python-headless-4.5.3.56 pathtools-0.1.2 pyDeprecate-0.3.0 pydantic-1.8.2 pyhocon-0.3.58 pytorch-lightning-1.3.8 pytorch-lightning-bolts-0.3.2 sentry-sdk-1.3.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 tensorboard-2.4.1 torchmetrics-0.4.1 wandb-0.10.33 yarl-1.6.3\n"
     ]
    }
   ],
   "source": [
    "!python install.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: prepare_dataset.py [-h] [--size SIZE] [--n_worker N_WORKER]\n",
      "                          [--resample RESAMPLE]\n",
      "                          path out\n",
      "\n",
      "Preprocess images for model training\n",
      "\n",
      "positional arguments:\n",
      "  path                 Path to the image dataset.\n",
      "  out                  Filename of the result lmdb dataset.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help           show this help message and exit\n",
      "  --size SIZE          Resolutions of images for the dataset. (default:\n",
      "                       256,512,1024)\n",
      "  --n_worker N_WORKER  Number of workers for preparing dataset. (default: 2)\n",
      "  --resample RESAMPLE  Resampling methods for resizing images. 'lanczos' or\n",
      "                       'bilinear' (default: lanczos)\n"
     ]
    }
   ],
   "source": [
    "!python scripts/prepare_dataset.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconverted_dataset = '/content/drive/MyDrive/dataset-creation/painterly-faces-v2'\n",
    "out_path = '/content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-512'\n",
    "dataset_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make dataset of image sizes: 512\n",
      "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:387: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "1158it [04:46,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "!python scripts/convert_dataset.py --size {dataset_size} {unconverted_dataset} {out_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/trainer.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 512\n",
    "dataset_location = '/content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-512'\n",
    "resume = 'rosinality-ffhq-280000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /content/drive/MyDrive/datasets-aliasfree/painterly-faces-v2-512\n",
      "Initialized MultiResolutionDataset dataset with 1158 images\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "{'style_dim': 512, 'n_mlp': 2, 'kernel_size': 3, 'n_taps': 6, 'filter_parameters': {'cutoffs': [2.0, 2.996614153753363, 4.489848193237492, 6.727171322029716, 10.079368399158984, 15.101989002907096, 22.627416997969522, 33.90281901949746, 50.79683366298237, 76.10925536017415, 114.03503592196346, 170.85950133376437, 256.0, 256.0], 'stopbands': [4.2870938501451725, 6.133313378678402, 8.774599837557007, 12.553345566348012, 17.95939277294997, 25.69353221962805, 36.758347359905116, 52.58818013349059, 75.23506600215094, 107.63474115247546, 153.98720461851096, 220.30116793454846, 315.1729698162986, 315.1729698162986], 'srs': [16, 16, 32, 32, 64, 64, 128, 128, 256, 256, 256, 256, 256, 256], 'band_halfs': [6.0, 5.003385846246637, 11.510151806762508, 9.272828677970285, 21.920631600841016, 16.898010997092904, 41.37258300203048, 30.097180980502543, 77.20316633701762, 51.890744639825854, 39.9521686965475, 49.44166660078409, 59.172969816298576, 59.172969816298576], 'channels': [512, 512, 512, 512, 256, 256, 128, 128, 64, 64, 64, 64, 64, 64]}}\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2021-07-26 23:31:08.040950: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 14.6 M\n",
      "1 | g_ema         | Generator     | 14.6 M\n",
      "2 | discriminator | Discriminator | 29.0 M\n",
      "------------------------------------------------\n",
      "58.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.769   Total estimated model params size (MB)\n",
      "Training: 0it [00:00, ?it/s]\n",
      "\n",
      "Resuming from: /content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/scripts/../pretrained/rosinality-ffhq-280000.pt\n",
      "\n",
      "{'n_gpu': 4, 'n_machine': 1, 'machine_rank': 0, 'dist_url': 'tcp://127.0.0.1:49152', 'distributed': True, 'ckpt': 'checkpoint/250000.pt', 'generator': {'__target': 'model.Generator', '__validate': True, '__partial': False, 'filter_parameters': {'__target': 'model.filter_parameters', '__validate': True, '__partial': False, 'channel_base': 16384, 'channel_max': 512, 'cutoff_0': 2, 'cutoff_n': 128, 'n_critical': 2, 'n_layer': 14, 'sr_max': 256, 'stopband_0': 4.2870938501451725, 'stopband_n': 157.5864849081493}, 'kernel_size': 3, 'lr_mlp': 0.01, 'margin': 10, 'n_mlp': 2, 'n_taps': 6, 'style_dim': 512}, 'discriminator': {'__target': 'stylegan2.model.Discriminator', '__validate': True, '__partial': False, 'channel_multiplier': 2, 'size': 256}, 'training': {'size': 256, 'iter': 800000, 'batch': 8, 'n_sample': 32, 'r1': 10.0, 'd_reg_every': 16, 'lr_g': 0.003, 'lr_d': 0.0025, 'augment': False, 'augment_p': 0.0, 'ada_target': 0.6, 'ada_length': 500000, 'ada_every': 256, 'start_iter': 250000}, 'path': '../stylegan2-pytorch/ffhq.lmdb', 'wandb': True, 'logger': 'rich'}\n",
      "Traceback (most recent call last):\n",
      "  File \"scripts/trainer.py\", line 84, in <module>\n",
      "    cli_main()\n",
      "  File \"scripts/trainer.py\", line 81, in cli_main\n",
      "    trainer.fit(model, train_loader)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 460, in fit\n",
      "    self._run(model)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 758, in _run\n",
      "    self.dispatch()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 799, in dispatch\n",
      "    self.accelerator.start_training(self)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 96, in start_training\n",
      "    self.training_type_plugin.start_training(trainer)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 144, in start_training\n",
      "    self._results = trainer.run_stage()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 809, in run_stage\n",
      "    return self.run_train()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 857, in run_train\n",
      "    self.train_loop.on_train_start()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\", line 101, in on_train_start\n",
      "    self.trainer.call_hook(\"on_train_start\")\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1235, in call_hook\n",
      "    output = hook_fx(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/scripts/../src/alias_free_gan.py\", line 94, in on_train_start\n",
      "    self.load_checkpoint(self.resume_path)\n",
      "  File \"/content/drive/MyDrive/afg-lightning-devel-checkpoint/alias-free-gan-pytorch-lightning/scripts/../src/alias_free_gan.py\", line 236, in load_checkpoint\n",
      "    self.generator.load_state_dict(checkpoint[\"g\"])\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1407, in load_state_dict\n",
      "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "RuntimeError: Error(s) in loading state_dict for Generator:\n",
      "\tsize mismatch for convs.2.activation.upsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "\tsize mismatch for convs.2.activation.downsample_filter: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.3.activation.upsample_filter: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.3.activation.downsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "\tsize mismatch for convs.4.conv.weight: copying a param with shape torch.Size([1, 512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 256, 512, 3, 3]).\n",
      "\tsize mismatch for convs.4.activation.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for convs.4.activation.upsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "\tsize mismatch for convs.4.activation.downsample_filter: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.5.conv.weight: copying a param with shape torch.Size([1, 256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 256, 256, 3, 3]).\n",
      "\tsize mismatch for convs.5.conv.modulation.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n",
      "\tsize mismatch for convs.5.conv.modulation.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for convs.5.activation.upsample_filter: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.5.activation.downsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "\tsize mismatch for convs.6.conv.weight: copying a param with shape torch.Size([1, 256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 128, 256, 3, 3]).\n",
      "\tsize mismatch for convs.6.activation.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for convs.6.activation.upsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "\tsize mismatch for convs.6.activation.downsample_filter: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.7.conv.weight: copying a param with shape torch.Size([1, 128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 128, 128, 3, 3]).\n",
      "\tsize mismatch for convs.7.conv.modulation.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([128, 512]).\n",
      "\tsize mismatch for convs.7.conv.modulation.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for convs.7.activation.upsample_filter: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.7.activation.downsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "\tsize mismatch for convs.8.conv.weight: copying a param with shape torch.Size([1, 128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 64, 128, 3, 3]).\n",
      "\tsize mismatch for convs.8.activation.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for convs.8.activation.upsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([24]).\n",
      "\tsize mismatch for convs.8.activation.downsample_filter: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.9.conv.weight: copying a param with shape torch.Size([1, 128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 64, 64, 3, 3]).\n",
      "\tsize mismatch for convs.9.conv.modulation.weight: copying a param with shape torch.Size([128, 512]) from checkpoint, the shape in current model is torch.Size([64, 512]).\n",
      "\tsize mismatch for convs.9.conv.modulation.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for convs.9.activation.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for convs.10.conv.weight: copying a param with shape torch.Size([1, 64, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 64, 64, 3, 3]).\n",
      "\tsize mismatch for convs.10.conv.modulation.weight: copying a param with shape torch.Size([128, 512]) from checkpoint, the shape in current model is torch.Size([64, 512]).\n",
      "\tsize mismatch for convs.10.conv.modulation.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for convs.10.activation.upsample_filter: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "\tsize mismatch for convs.10.activation.downsample_filter: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "Training: 0it [00:01, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "!python scripts/trainer.py \\\n",
    "    --size {model_size} \\\n",
    "    --gpus 1 \\\n",
    "    --dataset_path {dataset_location} \\\n",
    "    --resume_from {resume} \\\n",
    "    --logger True \\\n",
    "    --max_steps 800000 \\\n",
    "    --batch 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}